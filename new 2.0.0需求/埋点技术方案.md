# 埋点技术方案

## 一、方案概述

本方案旨在为Onchain板块和标签&精准推荐系统提供统一的埋点解决方案，确保数据收集的一致性和准确性，同时保持开发成本低、实现难度小。

### 目标需求

根据原始需求文档，主要埋点需求包括：

**Onchain板块**：

- 页面浏览埋点：Onchain落地页访问
- 操作行为埋点：导航栏点击、卡片点击等
- 统计数据：PV/UV、用户行为路径、任务完成率

**标签&精准推荐**：

- 展示和点击统计：View User数量、Click User数量
- 交互数据：展开/收起行为
- 投放效果统计：完成用户数量等

## 二、技术架构

### 整体架构

采用前端触发、Kafka中转、ClickHouse存储的埋点架构：

```mermaid
flowchart LR
    A[前端应用] -->|埋点事件| B[埋点收集SDK]
    B -->|HTTP请求| C[埋点收集服务]
    C -->|消息| D[Kafka]
    E[消费服务] -->|消费消息| D
    E -->|批量写入| F[ClickHouse]
    G[数据分析服务] -->|查询| F
    H[管理后台] -->|查看| G
```

### 关键组件

1. **前端埋点SDK**：轻量级客户端JS库
2. **埋点收集服务**：专用API接收埋点数据
3. **Kafka**：消息队列，缓冲埋点数据
4. **数据消费服务**：从Kafka读取并批量写入ClickHouse
5. **ClickHouse**：列式存储数据库，高效存储与查询埋点数据
6. **数据分析服务**：实现基本统计和分析
7. **可视化展示**：在管理后台展示分析结果

## 三、埋点事件定义

### 通用事件属性

所有埋点事件共享的基础属性：

| 属性名     | 类型   | 说明                  |
| ---------- | ------ | --------------------- |
| event_id   | String | 事件唯一标识          |
| user_id    | String | 用户ID                |
| timestamp  | Number | 事件时间戳(毫秒)      |
| platform   | String | 平台(web/ios/android) |
| page       | String | 当前页面路径          |
| session_id | String | 会话ID                |

### Onchain板块埋点事件

#### 页面访问事件

| 事件名称  | 触发时机     | 额外字段            | 说明         |
| --------- | ------------ | ------------------- | ------------ |
| page_view | 页面加载完成 | page_name: 页面名称 | 记录页面访问 |

#### 操作行为事件

| 事件名称        | 触发时机   | 额外字段              | 说明           |
| --------------- | ---------- | --------------------- | -------------- |
| navbar_click    | 导航栏点击 | target: 点击目标      | 导航栏交互     |
| card_click      | 卡片点击   | card_id: 卡片ID       | Action卡片点击 |
| action_start    | 开始Action | action_id: ActionID   | 用户开始任务   |
| action_complete | 完成Action | action_id: ActionID   | 用户完成任务   |
| reward_claim    | 领取奖励   | reward_type: 奖励类型 | 用户领取奖励   |

### 标签&精准推荐埋点事件

#### 展示和点击事件

| 事件名称                  | 触发时机               | 额外字段                                                      | 说明              |
| ------------------------- | ---------------------- | ------------------------------------------------------------- | ----------------- |
| recommend_impression      | 推荐内容展示在可视区域 | delivery_id: 投放ID `<br>`content_type: 内容类型            | 统计View User     |
| recommend_click           | 用户点击推荐内容       | delivery_id: 投放ID `<br>`content_type: 内容类型            | 统计Click User    |
| recommend_expand_collapse | 用户展开/收起推荐内容  | delivery_id: 投放ID `<br>`action: 动作类型(expand/collapse) | 记录展开/收起行为 |
| recommend_complete        | 用户完成推荐Action     | delivery_id: 投放ID `<br>`action_id: Action ID              | 统计Complete User |

## 四、埋点实现方案

### 前端实现

采用简单的包装方法实现埋点SDK：

```javascript
// 埋点SDK简化实现
const TrackSDK = {
  // 初始化
  init(config = {}) {
    this.config = {
      apiUrl: '/api/track',
      batchSize: 10,
      ...config
    };
    this.eventQueue = [];
    this.sessionId = this._generateSessionId();
  
    // 定时发送队列中的事件
    setInterval(() => this.flush(), 5000);
  
    // 页面关闭前发送
    window.addEventListener('beforeunload', () => this.flush(true));
  },
  
  // 触发事件
  track(eventName, properties = {}) {
    const event = {
      event_name: eventName,
      user_id: this._getUserId(),
      timestamp: Date.now(),
      platform: 'web',
      page: window.location.pathname,
      session_id: this.sessionId,
      ...properties
    };
  
    this.eventQueue.push(event);
  
    // 达到批量大小则发送
    if (this.eventQueue.length >= this.config.batchSize) {
      this.flush();
    }
  },
  
  // 发送事件到服务器
  flush(isSync = false) {
    if (this.eventQueue.length === 0) return;
  
    const events = [...this.eventQueue];
    this.eventQueue = [];
  
    const sendData = () => {
      fetch(this.config.apiUrl, {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({ events })
      }).catch(err => {
        console.error('埋点数据发送失败', err);
        // 失败后重新加入队列
        this.eventQueue.push(...events);
      });
    };
  
    if (isSync && navigator.sendBeacon) {
      // 使用sendBeacon保证页面关闭时数据发送
      navigator.sendBeacon(
        this.config.apiUrl, 
        new Blob([JSON.stringify({ events })], { type: 'application/json' })
      );
    } else {
      sendData();
    }
  },
  
  // 生成会话ID
  _generateSessionId() {
    return Date.now().toString(36) + Math.random().toString(36).substr(2);
  },
  
  // 获取用户ID
  _getUserId() {
    // 从全局状态或localStorage获取
    return window.userId || localStorage.getItem('userId') || 'anonymous';
  }
};
```

### 使用示例

```javascript
// 初始化埋点SDK
TrackSDK.init({
  apiUrl: '/api/track',
  batchSize: 10
});

// Onchain页面访问埋点
TrackSDK.track('page_view', { page_name: 'onchain_landing' });

// 导航栏点击埋点
document.querySelector('.navbar-onchain').addEventListener('click', () => {
  TrackSDK.track('navbar_click', { target: 'onchain' });
});

// 推荐内容展示埋点
function trackRecommendImpression(deliveryId, contentType) {
  // 使用IntersectionObserver检测元素可见性
  const observer = new IntersectionObserver((entries) => {
    entries.forEach(entry => {
      if (entry.isIntersecting) {
        TrackSDK.track('recommend_impression', {
          delivery_id: deliveryId,
          content_type: contentType
        });
        observer.disconnect(); // 只触发一次
      }
    });
  });
  
  observer.observe(document.querySelector(`[data-delivery-id="${deliveryId}"]`));
}
```

### 后端API实现

简单的埋点收集API与Kafka对接：

```javascript
package main

import (
	"encoding/json"
	"fmt"
	"log"
	"net/http"

	"github.com/Shopify/sarama"
	"github.com/gin-gonic/gin"
)

// 事件结构体
type Event struct {
	EventName  string                 `json:"event_name"`
	UserID     string                 `json:"user_id"`
	Timestamp  int64                  `json:"timestamp"`
	Platform   string                 `json:"platform"`
	Page       string                 `json:"page"`
	SessionID  string                 `json:"session_id"`
	Properties map[string]interface{} `json:"properties"`
}

// 请求体结构
type TrackRequest struct {
	Events []Event `json:"events"`
}

// Kafka生产者
var producer sarama.SyncProducer

func main() {
	// 初始化Kafka生产者
	config := sarama.NewConfig()
	config.Producer.RequiredAcks = sarama.WaitForAll
	config.Producer.Retry.Max = 3
	config.Producer.Return.Successes = true

	var err error
	producer, err = sarama.NewSyncProducer([]string{"kafka-broker:9092"}, config)
	if err != nil {
		log.Fatalf("创建Kafka生产者失败: %v", err)
	}
	defer producer.Close()

	// 初始化Gin路由
	r := gin.Default()
	r.POST("/api/track", handleTrackEvents)

	// 启动HTTP服务
	r.Run(":8080")
}

// 处理埋点事件的接口
func handleTrackEvents(c *gin.Context) {
	var req TrackRequest

	if err := c.ShouldBindJSON(&req); err != nil {
		c.JSON(http.StatusBadRequest, gin.H{"error": "无效的请求数据"})
		return
	}

	if len(req.Events) == 0 {
		c.JSON(http.StatusBadRequest, gin.H{"error": "无效的事件数据"})
		return
	}

	// 异步发送事件到Kafka
	go func() {
		if err := sendEventsToKafka(req.Events); err != nil {
			log.Printf("埋点发送到Kafka错误: %v", err)
		}
	}()

	// 立即返回成功，不阻塞用户操作
	c.JSON(http.StatusOK, gin.H{"success": true})
}

// 发送事件到Kafka
func sendEventsToKafka(events []Event) error {
	// 数据验证和清洗
	var validEvents []Event
	for _, event := range events {
		if validateEvent(event) {
			validEvents = append(validEvents, event)
		}
	}

	if len(validEvents) == 0 {
		return nil
	}

	// 发送到Kafka topic
	for _, event := range validEvents {
		eventJSON, err := json.Marshal(event)
		if err != nil {
			log.Printf("JSON序列化失败: %v", err)
			continue
		}

		message := &sarama.ProducerMessage{
			Topic: "tracking_events",
			Key:   sarama.StringEncoder(event.UserID),
			Value: sarama.ByteEncoder(eventJSON),
		}

		_, _, err = producer.SendMessage(message)
		if err != nil {
			return fmt.Errorf("发送消息到Kafka失败: %v", err)
		}
	}

	return nil
}

// 验证事件
func validateEvent(event Event) bool {
	// 基本字段验证
	if event.EventName == "" || event.Timestamp == 0 {
		return false
	}

	// 更多验证逻辑可以根据需要添加
	return true
}
```

## 五、埋点API设计

埋点API是前端SDK与后端数据处理系统之间的桥梁，需提供简单稳定的接口以确保埋点数据高效传输。

### 1. 埋点上报API

#### 接口定义

```
POST /api/v1/track
```

#### 请求头

| 参数名        | 必选 | 类型   | 说明                           |
| ------------- | ---- | ------ | ------------------------------ |
| Content-Type  | 是   | string | 固定值：application/json       |
| Authorization | 否   | string | 认证令牌，若启用安全验证则必填 |

#### 请求参数

```json
{
  "events": [
    {
      "event_name": "string",      // 事件名称，必填
      "user_id": "string",         // 用户ID，必填
      "timestamp": number,         // 事件时间戳(毫秒)，必填
      "platform": "string",        // 平台(web/ios/android)，必填
      "page": "string",            // 当前页面路径，必填
      "session_id": "string",      // 会话ID，必填
      "properties": {              // 自定义属性，选填
        "key1": "value1",
        "key2": "value2"
      }
    }
  ],
  "sdk_version": "string",       // SDK版本号，选填
  "app_version": "string",       // 应用版本号，选填
  "client_ip": "string"          // 客户端IP，选填（服务端会重写）
}
```

#### 响应参数

```json
{
  "code": 200,              // 状态码：200成功，其他错误
  "message": "success",     // 状态描述
  "request_id": "string",   // 请求ID，用于问题排查
  "processed_count": 5      // 处理的事件数量
}
```

#### 错误码说明

| 错误码 | 描述           | 处理建议              |
| ------ | -------------- | --------------------- |
| 200    | 成功           | 正常处理              |
| 400    | 请求参数错误   | 检查参数格式和必填项  |
| 401    | 认证失败       | 检查Authorization令牌 |
| 413    | 请求体过大     | 减少单次请求事件数量  |
| 429    | 请求频率过高   | 实施请求频率控制      |
| 500    | 服务器内部错误 | 重试或联系技术支持    |

#### 示例请求

```bash
curl -X POST "https://api.example.com/api/v1/track" \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9..." \
  -d '{
    "events": [
      {
        "event_name": "page_view",
        "user_id": "12345678",
        "timestamp": 1652345678901,
        "platform": "web",
        "page": "/onchain/landing",
        "session_id": "sess_abcdef123456",
        "properties": {
          "page_name": "onchain_landing",
          "referrer": "homepage"
        }
      }
    ],
    "sdk_version": "1.0.0",
    "app_version": "2.3.1"
  }'
```

#### 示例响应

```json
{
  "code": 200,
  "message": "success",
  "request_id": "req_xyz789012345",
  "processed_count": 1
}
```

### 2. 批量埋点上报API

为满足高频场景需求，提供批量上报接口，支持单次请求上传多条事件数据。

#### 接口定义

```
POST /api/v1/track/batch
```

与基础埋点API格式相同，但支持最多100条事件记录，并提供更高的吞吐能力。

### 3. 埋点调试API

用于前端开发人员调试埋点实现，提供即时反馈。

#### 接口定义

```
POST /api/v1/track/debug
```

#### 请求参数

与正常埋点API相同，增加debug=true参数。

#### 响应参数

```json
{
  "code": 200,
  "message": "success",
  "request_id": "string",
  "debug_info": {
    "validation_results": [
      {
        "event_index": 0,
        "valid": true,
        "errors": []
      }
    ],
    "processing_time_ms": 5,
    "would_be_stored": true
  }
}
```

### 4. 埋点健康检查API

用于监控埋点系统可用性。

#### 接口定义

```
GET /api/v1/track/health
```

#### 响应参数

```json
{
  "status": "healthy",
  "version": "1.0.0",
  "kafka_connected": true,
  "clickhouse_connected": true,
  "uptime_seconds": 3600
}
```

### 5. API安全与性能考虑

1. **API认证机制**：

   - 采用简单API Key + 时间戳签名认证机制
   - **认证参数**：
     ```
     app_id: 应用唯一标识
     timestamp: 当前UNIX时间戳(毫秒)
     sign: 签名，计算方式为 md5(app_id + timestamp + secret_key)
     ```
   - **请求示例**：
     ```json
     {
       "app_id": "onchain_app",
       "timestamp": 1693245789000,
       "sign": "a1b2c3d4e5f6g7h8i9j0",
       "events": [...]
     }
     ```
   - **前端实现**：
     ```javascript
     // 生成签名
     function generateSignature() {
       const APP_ID = 'onchain_app';
       const SECRET_KEY = 'your_app_secret'; // 应由后端安全分发
       const timestamp = Date.now();
       const sign = md5(APP_ID + timestamp + SECRET_KEY);

       return {
         app_id: APP_ID,
         timestamp: timestamp,
         sign: sign
       };
     }

     // 发送埋点请求
     function sendTrackEvent(event) {
       const auth = generateSignature();

       fetch('/api/v1/track', {
         method: 'POST',
         headers: { 'Content-Type': 'application/json' },
         body: JSON.stringify({
           ...auth,
           events: [event]
         })
       });
     }
     ```
   - **后端验证**：
     ```java
     // 验证签名
     boolean verifySignature(String appId, long timestamp, String sign) {
       // 1. 检查时间戳是否在有效期内(5分钟)
       long currentTime = System.currentTimeMillis();
       if (Math.abs(currentTime - timestamp) > 300000) {
         return false;
       }

       // 2. 获取应用密钥
       String secretKey = appKeyService.getSecretKey(appId);
       if (secretKey == null) {
         return false;
       }

       // 3. 重新计算签名并比较
       String expectedSign = md5(appId + timestamp + secretKey);
       return expectedSign.equals(sign);
     }
     ```
   - **安全增强**：
     - 为防止前端密钥泄露，可结合IP白名单和Referer/Origin验证
     - 高安全需求场景可使用临时令牌或后端代理方式
     - 定期轮换密钥提高安全性
2. **性能优化**：

   - 使用HTTP/2减少连接开销
   - 启用gzip压缩减少传输数据量
   - 支持keepalive连接
   - 服务端异步处理，快速响应客户端
3. **容错设计**：

   - 客户端实现指数退避重试
   - 服务端资源隔离，防止单一客户端影响系统稳定性
   - 熔断机制，在系统过载时保护核心功能
4. **可观测性**：

   - 每个API请求分配唯一request_id
   - 详细的请求日志记录
   - API调用量、错误率、响应时间等关键指标监控

## 六、数据去重机制

特别针对标签&精准推荐系统的需求，实现数据去重逻辑：

```javascript
package main

import (
	"context"
	"fmt"
	"log"
	"time"

	"github.com/ClickHouse/clickhouse-go/v2"
	"github.com/ClickHouse/clickhouse-go/v2/lib/driver"
)

// Event 定义事件结构
type Event struct {
	EventName  string                 `json:"event_name"`
	UserID     string                 `json:"user_id"`
	Timestamp  int64                  `json:"timestamp"`
	Platform   string                 `json:"platform"`
	Page       string                 `json:"page"`
	SessionID  string                 `json:"session_id"`
	Properties map[string]interface{} `json:"properties"`
}

// deduplicateEvents 对事件进行去重处理
func deduplicateEvents(ctx context.Context, events []Event, conn driver.Conn) ([]Event, error) {
	result := make([]Event, 0, len(events))
	uniqueKeys := make(map[string]struct{})

	for _, event := range events {
		// 对于推荐展示和点击事件，保证同一用户对同一投放只计算一次
		if event.EventName == "recommend_impression" || event.EventName == "recommend_click" {
			// 从properties中获取delivery_id
			deliveryID, ok := event.Properties["delivery_id"].(string)
			if !ok {
				// 如果没有delivery_id，继续处理下一条事件
				continue
			}

			// 构建唯一键
			key := fmt.Sprintf("%s_%s_%s", event.EventName, event.UserID, deliveryID)

			// 检查内存中是否已处理过
			if _, exists := uniqueKeys[key]; exists {
				continue
			}

			// 检查ClickHouse中是否已存在记录（过去24小时内）
			exists, err := checkEventExistenceInClickHouse(ctx, conn, event.EventName, event.UserID, deliveryID, 24*time.Hour)
			if err != nil {
				log.Printf("检查事件存在性时出错: %v", err)
				// 出错时仍然处理事件，不跳过
			} else if exists {
				// 如果已存在记录，跳过此事件
				continue
			}

			// 记录唯一键
			uniqueKeys[key] = struct{}{}
		}

		// 添加到结果集
		result = append(result, event)
	}

	return result, nil
}

// checkEventExistenceInClickHouse 检查ClickHouse中是否存在记录
func checkEventExistenceInClickHouse(ctx context.Context, conn driver.Conn, eventName, userID, deliveryID string, timeWindow time.Duration) (bool, error) {
	// 计算时间范围
	now := time.Now()
	startTime := now.Add(-timeWindow).Unix() * 1000 // 转换为毫秒时间戳

	// 查询ClickHouse
	query := `
		SELECT 1 FROM events 
		WHERE event_name = ? 
		AND user_id = ? 
		AND JSONExtractString(properties, 'delivery_id') = ? 
		AND timestamp >= ? 
		LIMIT 1
	`

	rows, err := conn.Query(ctx, query, eventName, userID, deliveryID, startTime)
	if err != nil {
		return false, fmt.Errorf("查询ClickHouse失败: %w", err)
	}
	defer rows.Close()

	// 如果有记录，则返回true
	return rows.Next(), nil
}

// 示例：创建ClickHouse连接的函数
func createClickHouseConnection() (driver.Conn, error) {
	conn, err := clickhouse.Open(&clickhouse.Options{
		Addr: []string{"clickhouse-server:9000"},
		Auth: clickhouse.Auth{
			Database: "default",
			Username: "default",
			Password: "",
		},
		Settings: clickhouse.Settings{
			"max_execution_time": 60,
		},
		DialTimeout: 5 * time.Second,
		Compression: &clickhouse.Compression{
			Method: clickhouse.CompressionLZ4,
		},
	})

	if err != nil {
		return nil, fmt.Errorf("连接ClickHouse失败: %w", err)
	}

	// 测试连接
	if err := conn.Ping(context.Background()); err != nil {
		return nil, fmt.Errorf("ClickHouse Ping失败: %w", err)
	}

	return conn, nil
}

// 使用示例
func processEvents(events []Event) ([]Event, error) {
	ctx := context.Background()

	// 创建ClickHouse连接
	conn, err := createClickHouseConnection()
	if err != nil {
		return nil, fmt.Errorf("创建ClickHouse连接失败: %w", err)
	}
	defer conn.Close()

	// 执行去重处理
	uniqueEvents, err := deduplicateEvents(ctx, events, conn)
	if err != nil {
		return nil, fmt.Errorf("事件去重处理失败: %w", err)
	}

	return uniqueEvents, nil
}
```

## 七、数据存储方案

采用ClickHouse高性能列式数据库存储埋点数据：

### 数据流转过程

1. 前端SDK收集埋点事件并发送到后端API
2. 后端API将事件写入Kafka消息队列
3. 消费服务从Kafka读取数据，进行去重和验证
4. 消费服务批量写入ClickHouse
5. 分析服务从ClickHouse读取数据进行统计分析

### ClickHouse表设计

**events表**（存储原始事件）：

```sql
CREATE TABLE events (
  event_id String,
  event_name String,
  user_id String,
  timestamp UInt64,
  event_date Date DEFAULT toDate(timestamp/1000),
  platform String,
  page String,
  session_id String,
  properties String, -- JSON格式存储额外属性
  created_at DateTime DEFAULT now()
) ENGINE = MergeTree()
PARTITION BY toYYYYMM(event_date)
ORDER BY (event_date, event_name, user_id)
TTL event_date + INTERVAL 3 MONTH; -- 数据保留3个月
```

**event_daily_stats表**（聚合统计表）：

```sql
CREATE MATERIALIZED VIEW event_daily_stats
ENGINE = SummingMergeTree()
PARTITION BY toYYYYMM(event_date)
ORDER BY (event_date, event_name, entity_id, entity_type)
POPULATE
AS SELECT
  event_date,
  event_name,
  JSONExtractString(properties, 'delivery_id') AS entity_id,
  'delivery' AS entity_type,
  count() AS event_count,
  uniqExact(user_id) AS unique_users
FROM events
WHERE event_name IN ('recommend_impression', 'recommend_click', 'recommend_complete')
  AND JSONHas(properties, 'delivery_id')
GROUP BY event_date, event_name, entity_id, entity_type;
```

**action_stats表**（Action统计表）：

```sql
CREATE MATERIALIZED VIEW action_stats
ENGINE = SummingMergeTree()
PARTITION BY toYYYYMM(event_date)
ORDER BY (event_date, action_id)
POPULATE
AS SELECT
  event_date,
  JSONExtractString(properties, 'action_id') AS action_id,
  sum(case when event_name = 'page_view' then 1 else 0 end) AS views,
  sum(case when event_name = 'action_start' then 1 else 0 end) AS starts,
  sum(case when event_name = 'action_complete' then 1 else 0 end) AS completions,
  uniqExact(user_id) AS unique_users
FROM events
WHERE event_name IN ('page_view', 'action_start', 'action_complete')
  AND JSONHas(properties, 'action_id')
GROUP BY event_date, action_id;
```

### Kafka配置

Kafka主题配置
topic.name=tracking_events
num.partitions=8
retention.ms=604800000 # 7天
compression.type=lz4

### 数据批量写入ClickHouse

```javascript
package main

import (
	"context"
	"encoding/json"
	"fmt"
	"log"
	"os"
	"os/signal"
	"sync"
	"syscall"
	"time"

	"github.com/ClickHouse/clickhouse-go/v2"
	"github.com/ClickHouse/clickhouse-go/v2/lib/driver"
	"github.com/Shopify/sarama"
)

// Event 事件结构
type Event struct {
	EventID    string                 `json:"event_id" ch:"event_id"`
	EventName  string                 `json:"event_name" ch:"event_name"`
	UserID     string                 `json:"user_id" ch:"user_id"`
	Timestamp  int64                  `json:"timestamp" ch:"timestamp"`
	Platform   string                 `json:"platform" ch:"platform"`
	Page       string                 `json:"page" ch:"page"`
	SessionID  string                 `json:"session_id" ch:"session_id"`
	Properties map[string]interface{} `json:"properties" ch:"-"`
	// 转换后的JSON字符串存储到ClickHouse
	PropertiesJSON string    `json:"-" ch:"properties"`
	CreatedAt      time.Time `json:"-" ch:"created_at"`
}

// 配置信息
type Config struct {
	KafkaBrokers    []string
	KafkaTopic      string
	KafkaGroup      string
	ClickHouseAddr  string
	ClickHouseDB    string
	ClickHouseUser  string
	ClickHousePass  string
	BatchSize       int
	CommitInterval  time.Duration
	MaxRetries      int
	RetryInterval   time.Duration
}

// 消费者结构
type Consumer struct {
	config        Config
	kafkaConsumer sarama.ConsumerGroup
	clickhouse    driver.Conn
	eventBatch    []Event
	batchMutex    sync.Mutex
	wg            sync.WaitGroup
	ctx           context.Context
	cancel        context.CancelFunc
}

// 创建新的消费者
func NewConsumer(config Config) (*Consumer, error) {
	// 创建上下文，支持取消操作
	ctx, cancel := context.WithCancel(context.Background())

	// 配置Kafka消费者
	kafkaConfig := sarama.NewConfig()
	kafkaConfig.Consumer.Return.Errors = true
	kafkaConfig.Consumer.Offsets.Initial = sarama.OffsetNewest

	// 创建Kafka消费者组
	kafkaConsumer, err := sarama.NewConsumerGroup(config.KafkaBrokers, config.KafkaGroup, kafkaConfig)
	if err != nil {
		cancel()
		return nil, fmt.Errorf("创建Kafka消费者失败: %w", err)
	}

	// 创建ClickHouse连接
	clickhouseConn, err := clickhouse.Open(&clickhouse.Options{
		Addr: []string{config.ClickHouseAddr},
		Auth: clickhouse.Auth{
			Database: config.ClickHouseDB,
			Username: config.ClickHouseUser,
			Password: config.ClickHousePass,
		},
		Settings: clickhouse.Settings{
			"max_execution_time": 60,
		},
		DialTimeout: 5 * time.Second,
		Compression: &clickhouse.Compression{
			Method: clickhouse.CompressionLZ4,
		},
		MaxOpenConns: 10,
		MaxIdleConns: 5,
	})
	if err != nil {
		cancel()
		kafkaConsumer.Close()
		return nil, fmt.Errorf("连接ClickHouse失败: %w", err)
	}

	// 测试ClickHouse连接
	if err := clickhouseConn.Ping(ctx); err != nil {
		cancel()
		kafkaConsumer.Close()
		return nil, fmt.Errorf("ClickHouse Ping失败: %w", err)
	}

	return &Consumer{
		config:        config,
		kafkaConsumer: kafkaConsumer,
		clickhouse:    clickhouseConn,
		eventBatch:    make([]Event, 0, config.BatchSize),
		ctx:           ctx,
		cancel:        cancel,
	}, nil
}

// 启动消费服务
func (c *Consumer) Start() error {
	log.Println("启动消费服务...")

	// 处理消费者错误
	go func() {
		for err := range c.kafkaConsumer.Errors() {
			log.Printf("Kafka消费者错误: %v", err)
		}
	}()

	// 启动定时提交器
	go c.periodicFlush()

	// 捕获终止信号
	signals := make(chan os.Signal, 1)
	signal.Notify(signals, syscall.SIGINT, syscall.SIGTERM)

	// 创建处理器
	handler := &kafkaHandler{
		consumer: c,
	}

	// 消费循环
	c.wg.Add(1)
	go func() {
		defer c.wg.Done()
		for {
			if err := c.kafkaConsumer.Consume(c.ctx, []string{c.config.KafkaTopic}, handler); err != nil {
				if err == sarama.ErrClosedConsumerGroup {
					log.Println("消费者组已关闭")
					return
				}
				log.Printf("消费错误: %v, 将在 %v 后重试", err, c.config.RetryInterval)
				select {
				case <-c.ctx.Done():
					return
				case <-time.After(c.config.RetryInterval):
					continue
				}
			}

			// 检查上下文是否被取消
			if c.ctx.Err() != nil {
				return
			}
		}
	}()

	// 等待终止信号
	select {
	case <-signals:
		log.Println("接收到终止信号，关闭服务...")
		c.Stop()
	case <-c.ctx.Done():
		log.Println("上下文取消，关闭服务...")
	}

	return nil
}

// 停止消费服务
func (c *Consumer) Stop() {
	c.cancel()
	c.kafkaConsumer.Close()
	// 刷新剩余数据
	if err := c.flush(); err != nil {
		log.Printf("最终刷新数据失败: %v", err)
	}
	c.wg.Wait()
	log.Println("消费服务已停止")
}

// 定期刷新批处理数据
func (c *Consumer) periodicFlush() {
	ticker := time.NewTicker(c.config.CommitInterval)
	defer ticker.Stop()

	for {
		select {
		case <-ticker.C:
			if err := c.flush(); err != nil {
				log.Printf("定期刷新数据失败: %v", err)
			}
		case <-c.ctx.Done():
			return
		}
	}
}

// 添加事件到批处理队列
func (c *Consumer) addEvent(event Event) {
	c.batchMutex.Lock()
	defer c.batchMutex.Unlock()

	// 序列化Properties为JSON字符串
	if event.Properties != nil {
		propertiesJSON, err := json.Marshal(event.Properties)
		if err != nil {
			log.Printf("序列化Properties失败: %v", err)
		} else {
			event.PropertiesJSON = string(propertiesJSON)
		}
	}

	// 设置创建时间
	event.CreatedAt = time.Now()

	c.eventBatch = append(c.eventBatch, event)

	// 如果达到批处理大小，刷新数据
	if len(c.eventBatch) >= c.config.BatchSize {
		if err := c.flush(); err != nil {
			log.Printf("批量刷新数据失败: %v", err)
		}
	}
}

// 刷新批处理数据到ClickHouse
func (c *Consumer) flush() error {
	c.batchMutex.Lock()
	defer c.batchMutex.Unlock()

	if len(c.eventBatch) == 0 {
		return nil
	}

	log.Printf("刷新 %d 条事件到ClickHouse", len(c.eventBatch))

	// 去重处理
	uniqueEvents, err := deduplicateEvents(c.ctx, c.eventBatch, c.clickhouse)
	if err != nil {
		return fmt.Errorf("事件去重失败: %w", err)
	}

	if len(uniqueEvents) == 0 {
		c.eventBatch = c.eventBatch[:0]
		return nil
	}

	// 批量插入ClickHouse
	batch, err := c.clickhouse.PrepareBatch(c.ctx, "INSERT INTO events")
	if err != nil {
		return fmt.Errorf("准备批量插入失败: %w", err)
	}

	// 添加所有事件到批处理
	for _, event := range uniqueEvents {
		err := batch.AppendStruct(&event)
		if err != nil {
			return fmt.Errorf("添加事件到批处理失败: %w", err)
		}
	}

	// 执行批量插入
	if err := batch.Send(); err != nil {
		// 重试逻辑
		for i := 0; i < c.config.MaxRetries; i++ {
			log.Printf("批量插入失败, 重试 %d/%d: %v", i+1, c.config.MaxRetries, err)
			time.Sleep(c.config.RetryInterval)

			// 创建新的批处理
			batch, err := c.clickhouse.PrepareBatch(c.ctx, "INSERT INTO events")
			if err != nil {
				continue
			}

			// 重新添加事件
			for _, event := range uniqueEvents {
				if err := batch.AppendStruct(&event); err != nil {
					break
				}
			}

			// 尝试再次发送
			if err := batch.Send(); err == nil {
				// 成功发送
				c.eventBatch = c.eventBatch[:0]
				return nil
			}
		}
		return fmt.Errorf("批量插入重试耗尽: %w", err)
	}

	// 清空批处理队列
	c.eventBatch = c.eventBatch[:0]
	return nil
}

// Kafka处理器
type kafkaHandler struct {
	consumer *Consumer
}

// Setup 是ConsumerGroupHandler接口的一部分
func (h *kafkaHandler) Setup(sarama.ConsumerGroupSession) error {
	return nil
}

// Cleanup 是ConsumerGroupHandler接口的一部分
func (h *kafkaHandler) Cleanup(sarama.ConsumerGroupSession) error {
	return nil
}

// ConsumeClaim 处理消费者声明
func (h *kafkaHandler) ConsumeClaim(session sarama.ConsumerGroupSession, claim sarama.ConsumerGroupClaim) error {
	for {
		select {
		case msg, ok := <-claim.Messages():
			if !ok {
				return nil
			}

			// 解析消息为事件
			var event Event
			if err := json.Unmarshal(msg.Value, &event); err != nil {
				log.Printf("解析事件失败: %v", err)
			} else {
				// 添加到批处理队列
				h.consumer.addEvent(event)
			}

			// 标记消息已处理
			session.MarkMessage(msg, "")

		case <-h.consumer.ctx.Done():
			return nil
		}
	}
}

// 主函数
func main() {
	// 配置
	config := Config{
		KafkaBrokers:    []string{"kafka-broker:9092"},
		KafkaTopic:      "tracking_events",
		KafkaGroup:      "tracking-group",
		ClickHouseAddr:  "clickhouse-server:9000",
		ClickHouseDB:    "default",
		ClickHouseUser:  "default",
		ClickHousePass:  "",
		BatchSize:       100,          // 一次批量处理的事件数
		CommitInterval:  time.Second * 5, // 强制提交间隔
		MaxRetries:      3,               // 最大重试次数
		RetryInterval:   time.Second * 2, // 重试间隔
	}

	// 创建消费者
	consumer, err := NewConsumer(config)
	if err != nil {
		log.Fatalf("创建消费者失败: %v", err)
	}

	// 启动消费服务
	if err := consumer.Start(); err != nil {
		log.Fatalf("启动消费服务失败: %v", err)
	}
}
```

## 八、埋点规范

为确保埋点数据质量和一致性，定义以下埋点规范：

### 命名规范

1. **事件名称**：

   - 使用小写字母和下划线，如 `page_view`，`button_click`
   - 使用动词_名词结构，如 `view_page`，`click_button`
   - 避免使用缩写，除非是广泛接受的术语(如PV、UV)
2. **属性名称**：

   - 使用驼峰命名法，如 `userId`，`pageNumber`
   - 名称应自描述，避免过度简化
   - 布尔类型属性使用 `is`或 `has`前缀，如 `isLoggedIn`，`hasPermission`
3. **特殊值**：

   - 使用英文，不使用中文或其他非ASCII字符
   - 枚举值使用全小写字母，单词间用下划线分隔
   - 时间戳统一使用毫秒级Unix时间戳

### 采集范围规范

1. **必采事件**：

   - 页面浏览（page_view）：所有页面必须采集
   - 点击事件（click）：关键功能按钮必须采集
   - 表单提交（form_submit）：所有表单提交必须采集
   - 错误事件（error）：所有前端错误必须采集
2. **可选事件**：

   - 页面停留时长（page_duration）：重要页面推荐采集
   - 元素曝光（element_exposure）：关键元素推荐采集
   - 滚动深度（scroll_depth）：内容型页面推荐采集
3. **禁止采集**：

   - 用户敏感信息（密码、私钥等）
   - 完整的个人身份信息
   - 高频触发事件（如鼠标移动）

### 实施流程规范

1. **埋点设计**：

   - 产品提出埋点需求
   - 数据团队评审埋点方案
   - 开发团队确认技术可行性
   - 形成埋点需求文档
2. **埋点开发**：

   - 前端/后端分别实现埋点代码
   - 开发环境进行埋点验证
   - 代码审核确保埋点质量
3. **埋点测试**：

   - 测试环境验证埋点触发逻辑
   - 验证数据完整性和准确性
   - 检查埋点性能影响
4. **埋点上线**：

   - 灰度发布埋点代码
   - 监控埋点数据量和质量
   - 持续优化埋点实现

### 质量保障规范

1. **数据验证**：

   - 所有埋点事件必须有唯一标识
   - 所有必填字段不得为空
   - 数据类型必须符合定义
2. **性能控制**：

   - 单次请求埋点数据量不超过50KB
   - 埋点不应影响页面加载和交互性能
   - 批量发送优于实时发送
3. **异常处理**：

   - 埋点失败不应影响业务功能
   - 临时存储并重试失败的埋点
   - 记录并监控埋点异常

## 九、数据查询API

针对运营与B端需求，提供以下API：

### 推荐效果统计API

GET /api/stats/delivery/{deliveryId}

返回示例：

```json
{
  "delivery_id": "123456",
  "target_users": 5000,
  "viewed_users": 3200,
  "clicked_users": 850,
  "completed_users": 320,
  "view_rate": 0.64,
  "click_rate": 0.27,
  "completion_rate": 0.10,
  "daily_stats": [
    {"date": "2023-05-01", "views": 750, "clicks": 200, "completions": 75},
    {"date": "2023-05-02", "views": 820, "clicks": 220, "completions": 82}
  ]
}
```

### Onchain任务统计API

GET /api/stats/action/{actionId}

返回示例：

```json
{
  "action_id": "789012",
  "page_views": 9500,
  "card_clicks": 2800,
  "starts": 1200,
  "completions": 950,
  "conversion_rate": 0.79,
  "daily_stats": [
    {"date": "2023-05-01", "views": 2000, "starts": 300, "completions": 240},
    {"date": "2023-05-02", "views": 1800, "starts": 280, "completions": 210}
  ]
}
```

## 十、实施计划

### 基础埋点框架

1. 设计并开发前端埋点SDK
2. 实现基础埋点收集API
3. 搭建数据存储基础架构
4. 实现通用埋点事件（页面访问、点击等）

### 业务埋点实现

1. 实现Onchain板块特定埋点
2. 实现标签&精准推荐埋点
3. 实现数据去重和质量控制逻辑
4. 开发基础统计API

### 数据分析统计

1. 实现数据聚合和统计功能
2. 开发运营后台数据展示
3. 开发B端数据展示

## 十一、注意事项

1. **性能考虑**：

   - 客户端埋点采用批量发送减少请求数
   - 服务端异步处理避免阻塞
   - 适当使用缓存减少数据库压力
2. **数据准确性**：

   - 确保事件去重逻辑正确实现
   - 设置合理的会话周期（如24小时）
   - 防抖机制避免短时间重复触发
3. **数据安全**：

   - 不采集用户敏感信息
   - 数据传输采用HTTPS
   - 实施适当的数据访问控制
4. **扩展性**：

   - 埋点事件定义支持灵活扩展
   - 存储方案考虑未来数据量增长
   - API设计预留扩展参数

## 十二、总结

本技术方案提供了一个高效、可靠的埋点解决方案，能够满足Onchain板块和标签&精准推荐系统的埋点需求。方案采用前端SDK收集数据，Kafka消息队列做缓冲，ClickHouse高效存储分析，通过批量处理和去重机制确保数据的准确性和效率，同时提供了必要的数据分析API支持业务需求。
