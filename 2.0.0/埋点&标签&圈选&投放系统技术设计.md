# C端标签系统技术选型与可行性分析

## 一、项目需求概述

根据1.9.8需求文档，需要开发一个功能完善的C端标签系统，主要用于精准推荐和用户分群。系统需要处理和分析以下数据：

- 用户基本信息（账户属性、社交媒体绑定、钱包绑定等）
- POH信息（身份验证和KYC认证信息）
- 链上数据（钱包活动、持币情况、交易历史等）
- 平台交互数据（Quest完成情况、Community参与度等）
- 用户偏好数据（浏览偏好、任务类型偏好等）
- Onchain行为数据（链上交互行为）

系统需要支持运营人员创建复杂的标签组合，进行精准用户筛选，并应用于投放推荐。

## 二、当前技术架构概述

目前业务系统架构：

- 业务数据存储：MySQL
- 数据分析平台：ClickHouse（业务数据已实现同步）

## 三、技术选型方案

### 1. 系统架构选型

#### 推荐方案：分层微服务架构

```
┌─────────────────────────────────────────────────────────────┐
│                      前端应用层                             │
└───────────────────────────────┬─────────────────────────────┘
                                │
┌───────────────────────────────┼─────────────────────────────┐
│                          API网关层                          │
└───────────────────────────────┼─────────────────────────────┘
                                │
┌───────────────┬───────────────┼───────────────┬─────────────┐
│  标签管理服务  │  用户特征服务  │   投放服务    │  埋点服务   │
└─────┬─────────┴────────┬──────┴─────┬─────────┴──────┬──────┘
      │                  │            │                │
┌─────┴──────────────────┴────────────┴────────────────┴──────┐
│                         消息队列层                          │
└─────┬──────────────────┬────────────┬────────────────┬──────┘
      │                  │            │                │
┌─────┴─────────┬────────┴──────┬─────┴─────────┬──────┴──────┐
│  数据采集服务  │  定时任务服务  │  数据计算服务  │ 数据存储服务│
└───────────────┴───────────────┴───────────────┴─────────────┘
```

#### 微服务详细设计：

##### 1) 标签管理服务 (Label Management Service)

**职责**：

- 管理标签元数据（创建、更新、删除标签定义）
- 执行标签条件到SQL转换
- 处理标签查询请求
- 管理标签权限和访问控制

**关键API**：

- `/labels` - 标签CRUD操作
- `/labels/{id}/users` - 获取具有特定标签的用户列表
- `/labels/filter` - 根据复杂条件筛选用户

**数据流**：

- 读取用户特征宽表数据
- 将标签规则转换为ClickHouse查询
- 将新标签定义写入MySQL元数据存储

**与《运营后台-自定义标签+精准推荐》对应的功能实现**：

- 完整支持Label List页面的功能需求
- 实现Save as Label的保存和查询功能
- 支持标签编辑和用户筛选条件组合

##### 2) 用户特征服务 (User Feature Service)

**职责**：

- 汇总和维护用户特征宽表
- 提供用户特征数据查询接口
- 处理用户特征字段的读取和更新
- 协调特征计算任务的执行

**关键API**：

- `/users` - 用户列表和筛选
- `/users/{id}/features` - 获取用户完整特征数据
- `/users/{id}/feature/{name}` - 获取用户特定特征
- `/users/batch/features` - 批量获取多用户特征

**数据流**：

- 定期从MySQL同步基础用户数据
- 从链上数据源获取EVM数据
- 从行为数据源获取Onchain行为数据
- 将数据汇总至ClickHouse特征宽表
- 提供特征查询服务

**与需求文档对应的功能实现**：

- 完整覆盖《C端标签系统 - Onchain特征表.csv》中的字段
- 支持User List页面的全部筛选和展示功能
- 实现POH信息的更新和有效期管理

##### 3) 投放服务 (Delivery Service)

**职责**：

- 管理精准推荐投放任务
- 处理投放内容配置和调度
- 提供投放效果统计和分析
- 管理投放生命周期和状态转换

**关键API**：

- `/deliveries` - 投放任务CRUD操作
- `/deliveries/{id}/stats` - 获取投放效果统计
- `/deliveries/active` - 获取当前生效的投放
- `/deliveries/{id}/approve` - 审批投放任务

**数据流**：

- 从标签服务获取目标用户集
- 将投放配置存储到MySQL
- 从埋点服务获取投放效果数据

**与需求文档对应的功能实现**：

- 完整实现《运营后台-自定义标签+精准推荐》中的Delivery功能
- 支持《c端精准推荐》中的曝光逻辑和交互样式
- 实现《Onchain新板块框架文档》中的Task推送工作流

##### 4) 埋点服务 (Tracking Service)

**职责**：

- 收集和处理用户行为埋点数据
- 提供埋点SDK和API接口
- 汇总行为统计和特征计算的原始数据
- 管理埋点质量和监控

**关键API**：

- `/events` - 接收埋点事件
- `/events/batch` - 批量接收埋点事件
- `/events/schema` - 获取埋点事件结构定义
- `/events/stats` - 获取埋点统计信息

**数据流**：

- 从前端/APP收集用户交互埋点
- 从后端服务收集业务事件埋点
- 将原始埋点数据写入ClickHouse
- 通过消息队列触发计算

**与需求文档对应的功能实现**：

- 支持《c端精准推荐》中的用户行为跟踪
- 实现《运营后台-自定义标签+精准推荐》中的用户行为统计
- 收集《Onchain新板块框架文档》中用户完成任务的行为数据

#### 5) 定时任务服务 (Scheduled Task Service)

**职责**：

- 调度和执行各类定时计算任务
- 管理特征计算和数据更新作业
- 监控任务执行状态和性能
- 处理任务失败和重试

**关键功能**：

- 用户特征定时计算作业
- 链上数据定期同步作业
- 标签结果集定期刷新作业
- POH信息有效期检查作业

**数据流**：

- 从配置中读取任务定义
- 按照设定的频率触发任务
- 将任务执行结果写入日志
- 将计算结果写入目标存储

**与需求文档对应的功能实现**：

- 实现《C端标签系统 - Onchain特征表.csv》中各字段的更新频率要求
- 支持《运营后台-自定义标签+精准推荐》中的数据统计需求
- 实现《Onchain新板块框架文档》中的数据分析需求

#### 可行性分析：

- **优势**：

  - 高度模块化，服务间边界清晰，便于团队独立开发和维护
  - 服务可以根据负载单独扩展，例如标签查询和投放服务可能需要更高的并发支持
  - 分离关注点，将复杂系统分解为可管理的组件
  - 支持不同服务采用最适合的技术栈和存储方案
- **挑战**：

  - 微服务间通信需要良好设计，避免性能瓶颈
  - 分布式系统的测试和监控复杂度增加
  - 需要处理分布式事务和数据一致性问题
- **适应性**：

  - 满足业务快速迭代需求，各模块可以独立演进
  - 支持按需扩展，例如可以先开发标签和投放核心功能，再逐步完善其他服务
  - 适应高并发访问场景，特别是C端推荐展示和标签筛选等高频操作

### 2. 数据存储技术选型

#### 推荐方案：MySQL + ClickHouse

| 存储系统   | 用途                                                                                                      |
| ---------- | --------------------------------------------------------------------------------------------------------- |
| MySQL      | - 业务操作数据（用户、角色、权限等）`<br>` - 标签元数据（标签定义、规则、关系） `<br>` - 投放任务数据 |
| ClickHouse | - 用户行为数据 `<br>` - 特征宽表存储 `<br>` - 大规模数据分析和标签计算                                |

#### 数据模型设计

##### MySQL 表设计

**1. 标签系统表**

```sql
-- 标签定义表
CREATE TABLE labels (
    id BIGINT PRIMARY KEY AUTO_INCREMENT,
    name VARCHAR(100) NOT NULL COMMENT '标签名称',
    creator_id BIGINT NOT NULL COMMENT '创建者ID',
    create_time DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP,
    update_time DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
    filter_conditions JSON NOT NULL COMMENT '筛选条件JSON',
    description VARCHAR(255) DEFAULT NULL COMMENT '标签描述',
    status TINYINT NOT NULL DEFAULT 1 COMMENT '状态：1-启用，0-禁用',
    user_count INT NOT NULL DEFAULT 0 COMMENT '标签匹配的用户数量',
    UNIQUE KEY (name),
    KEY idx_creator (creator_id),
    KEY idx_status (status),
    KEY idx_create_time (create_time)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COMMENT='标签定义表';

-- 标签用户映射表
CREATE TABLE label_user_mapping (
    label_id BIGINT NOT NULL COMMENT '标签ID',
    user_id BIGINT NOT NULL COMMENT '用户ID',
    update_time DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT '更新时间',
    PRIMARY KEY (label_id, user_id),
    KEY idx_user_id (user_id),
    KEY idx_update_time (update_time)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COMMENT='标签用户映射表，存储标签与用户的对应关系';
```

**2. 投放系统表**

```sql
-- 投放任务表
CREATE TABLE deliveries (
    id BIGINT PRIMARY KEY AUTO_INCREMENT,
    label_id BIGINT NOT NULL COMMENT '目标标签ID',
    creator_id BIGINT NOT NULL COMMENT '创建者ID',
    content_type ENUM('onchain_task', 'custom') NOT NULL COMMENT '内容类型',
    content_id BIGINT DEFAULT NULL COMMENT '内容ID，对应Onchain Task',
    custom_image VARCHAR(255) DEFAULT NULL COMMENT '自定义图片URL',
    custom_url VARCHAR(255) DEFAULT NULL COMMENT '自定义跳转URL',
    start_time DATETIME NOT NULL COMMENT '开始时间',
    end_time DATETIME NOT NULL COMMENT '结束时间',
    status ENUM('draft', 'pending', 'unpass', 'upcoming', 'ongoing', 'ended', 'expired', 'canceled') NOT NULL DEFAULT 'draft' COMMENT '状态',
    create_time DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP,
    update_time DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
    approval_id BIGINT DEFAULT NULL COMMENT '审批ID',
    KEY idx_label_id (label_id),
    KEY idx_creator_id (creator_id),
    KEY idx_status (status),
    KEY idx_time_range (start_time, end_time),
    KEY idx_content (content_type, content_id)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COMMENT='投放任务表';

-- 投放效果表
CREATE TABLE delivery_stats (
    delivery_id BIGINT NOT NULL,
    date DATE NOT NULL,
    target_user_count INT NOT NULL DEFAULT 0 COMMENT '目标用户数',
    impression_count INT NOT NULL DEFAULT 0 COMMENT '展示次数',
    unique_impression_count INT NOT NULL DEFAULT 0 COMMENT '独立用户展示次数',
    click_count INT NOT NULL DEFAULT 0 COMMENT '点击次数',
    unique_click_count INT NOT NULL DEFAULT 0 COMMENT '独立用户点击次数',
    complete_count INT NOT NULL DEFAULT 0 COMMENT '完成任务次数',
    unique_complete_count INT NOT NULL DEFAULT 0 COMMENT '独立用户完成次数',
    update_time DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
    PRIMARY KEY (delivery_id, date),
    KEY idx_update_time (update_time)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COMMENT='投放效果统计表';
```

**3. POH验证信息表**

```sql
-- POH验证信息表
CREATE TABLE poh_verifications (
    user_id BIGINT NOT NULL,
    has_zkme BOOLEAN NOT NULL DEFAULT FALSE COMMENT 'ZKMe NFT验证',
    has_babt BOOLEAN NOT NULL DEFAULT FALSE COMMENT 'Binance BABT验证',
    has_galxe_passport BOOLEAN NOT NULL DEFAULT FALSE COMMENT 'Galxe passport验证',
    has_binance_kyc BOOLEAN NOT NULL DEFAULT FALSE COMMENT 'Binance KYC验证',
    has_okx_kyc BOOLEAN NOT NULL DEFAULT FALSE COMMENT 'OKX KYC验证',
    has_coinbase_kyc BOOLEAN NOT NULL DEFAULT FALSE COMMENT 'Coinbase KYC验证',
    has_bybit_kyc BOOLEAN NOT NULL DEFAULT FALSE COMMENT 'Bybit KYC验证',
    has_gate_kyc BOOLEAN NOT NULL DEFAULT FALSE COMMENT 'Gate KYC验证',
    has_kucoin_kyc BOOLEAN NOT NULL DEFAULT FALSE COMMENT 'Kucoin KYC验证',
    -- KYC有效期字段
    binance_kyc_expire_time DATETIME DEFAULT NULL COMMENT 'Binance KYC过期时间',
    okx_kyc_expire_time DATETIME DEFAULT NULL COMMENT 'OKX KYC过期时间',
    coinbase_kyc_expire_time DATETIME DEFAULT NULL COMMENT 'Coinbase KYC过期时间',
    bybit_kyc_expire_time DATETIME DEFAULT NULL COMMENT 'Bybit KYC过期时间',
    gate_kyc_expire_time DATETIME DEFAULT NULL COMMENT 'Gate KYC过期时间',
    kucoin_kyc_expire_time DATETIME DEFAULT NULL COMMENT 'Kucoin KYC过期时间',
    create_time DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP,
    update_time DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
    PRIMARY KEY (user_id),
    KEY idx_update_time (update_time)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COMMENT='POH验证信息表';
```

**4. 审批流程表**

```sql
-- 审批流程表
CREATE TABLE approvals (
    id BIGINT PRIMARY KEY AUTO_INCREMENT,
    type ENUM('delivery_create', 'delivery_edit', 'delivery_cancel', 'onchain_task') NOT NULL COMMENT '审批类型',
    target_id BIGINT NOT NULL COMMENT '审批目标ID',
    requester_id BIGINT NOT NULL COMMENT '申请人ID',
    approver_id BIGINT DEFAULT NULL COMMENT '审批人ID',
    status ENUM('pending', 'approved', 'rejected') NOT NULL DEFAULT 'pending' COMMENT '审批状态',
    request_time DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT '申请时间',
    approve_time DATETIME DEFAULT NULL COMMENT '审批时间',
    request_data JSON NOT NULL COMMENT '申请数据',
    approve_comment VARCHAR(255) DEFAULT NULL COMMENT '审批意见',
    KEY idx_type_target (type, target_id),
    KEY idx_requester (requester_id),
    KEY idx_approver (approver_id),
    KEY idx_status (status),
    KEY idx_request_time (request_time)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COMMENT='审批流程表';
```

##### ClickHouse 表设计

**1. 用户特征宽表**

```sql
-- 用户特征宽表
CREATE TABLE user_features (
    user_id UInt64,
    last_active_time DateTime COMMENT '最后活跃时间',
    -- POH信息
    has_poh Bool DEFAULT false COMMENT '是否有POH验证',
    has_zkme Bool DEFAULT false COMMENT '是否有ZKMe NFT',
    has_babt Bool DEFAULT false COMMENT '是否有Binance BABT',
    has_galxe_passport Bool DEFAULT false COMMENT '是否有Galxe passport',
    has_binance_kyc Bool DEFAULT false COMMENT '是否有Binance KYC',
    has_okx_kyc Bool DEFAULT false COMMENT '是否有OKX KYC',
    has_coinbase_kyc Bool DEFAULT false COMMENT '是否有Coinbase KYC',
    has_bybit_kyc Bool DEFAULT false COMMENT '是否有Bybit KYC',
    has_gate_kyc Bool DEFAULT false COMMENT '是否有Gate KYC',
    has_kucoin_kyc Bool DEFAULT false COMMENT '是否有Kucoin KYC',
    -- 链上数据EVM
    first_activity_time Nullable(DateTime) COMMENT '钱包首次活动时间',
    total_tx_count Nullable(UInt32) COMMENT '总交易笔数',
    balance_usd Nullable(Float64) COMMENT '钱包余额(USD)',
    erc20_token_holdings Nullable(String) COMMENT 'ERC20 Token持有情况，JSON格式',
    native_token_holdings Nullable(String) COMMENT '原生代币持有情况，JSON格式',
    total_tx_value_usd Nullable(Float64) COMMENT '总交易价值(USD)',
    thirdwave_wallet_score Nullable(UInt8) COMMENT 'Thirdwave钱包评分，0-100',
    nft_holder_score Nullable(UInt8) COMMENT 'NFT持有评分，0-100',
    onchain_participation_score Nullable(UInt8) COMMENT '链上参与度评分，0-100',
    bot_warning Bool DEFAULT false COMMENT '机器人预警',
    transaction_pattern_high_velocity Bool DEFAULT false COMMENT '高频操作模式',
    transaction_pattern_timed Bool DEFAULT false COMMENT '定时操作模式',
    transaction_pattern_continuous Bool DEFAULT false COMMENT '连续操作模式',
    transaction_pattern_funding_network Bool DEFAULT false COMMENT '资金网络模式',
    associated_wallets Nullable(String) COMMENT '关联钱包，JSON数组',
    active_chains Nullable(String) COMMENT '活跃链，JSON数组',
    -- Onchain行为
    onchain_action_total UInt32 DEFAULT 0 COMMENT 'Onchain行为总数',
    onchain_action_30d UInt32 DEFAULT 0 COMMENT '30天内Onchain行为数',
    onchain_action_7d UInt32 DEFAULT 0 COMMENT '7天内Onchain行为数',
    onchain_quest_total UInt32 DEFAULT 0 COMMENT 'Onchain quest总数',
    onchain_task_total UInt32 DEFAULT 0 COMMENT 'Onchain task总数',
    -- 计算字段
    data_update_time DateTime DEFAULT now() COMMENT '数据更新时间',
    data_source String DEFAULT '' COMMENT '数据来源'
) ENGINE = ReplacingMergeTree(data_update_time)
PARTITION BY toYYYYMM(data_update_time)
ORDER BY (user_id);
```

**2. 用户行为事件表**

```sql
-- 用户行为事件表
CREATE TABLE user_events (
    event_id UUID DEFAULT generateUUIDv4(),
    event_time DateTime DEFAULT now(),
    user_id UInt64,
    event_type String COMMENT '事件类型',
    page String DEFAULT '' COMMENT '页面',
    element String DEFAULT '' COMMENT '元素',
    delivery_id Nullable(UInt64) COMMENT '投放ID',
    onchain_task_id Nullable(UInt64) COMMENT 'Onchain任务ID',
    action String DEFAULT '' COMMENT '行为',
    result String DEFAULT '' COMMENT '结果',
    duration_ms Nullable(UInt32) COMMENT '持续时间(毫秒)',
    extra_properties String DEFAULT '{}' COMMENT '额外属性，JSON格式',
    client_ip String DEFAULT '',
    user_agent String DEFAULT '',
    insert_time DateTime DEFAULT now()
) ENGINE = MergeTree()
PARTITION BY toYYYYMMDD(event_time)
ORDER BY (user_id, event_time);
```

**3. 标签用户物化视图**

```sql
-- 标签用户物化视图示例（动态标签）
CREATE MATERIALIZED VIEW mv_active_onchain_users
ENGINE = ReplacingMergeTree()
PARTITION BY toYYYYMM(update_time)
ORDER BY (user_id)
POPULATE
AS SELECT
    user_id,
    1001 as label_id, -- 活跃Onchain用户标签ID
    now() as update_time
FROM user_features
WHERE onchain_action_30d >= 3;
```

#### 数据聚合与流转设计

##### 1. 用户基础特征数据聚合流程

```
┌───────────────┐       ┌───────────────┐       ┌───────────────┐
│  MySQL用户表  │  →→→  │ 数据转换服务   │  →→→  │ 特征宽表预处理 │
└───────────────┘       └───────────────┘       └───────┬───────┘
                                                         │
┌───────────────┐       ┌───────────────┐       ┌───────▼───────┐
│  POH验证表    │  →→→  │ POH数据处理   │  →→→  │               │
└───────────────┘       └───────────────┘       │               │
                                                 │  ClickHouse  │
┌───────────────┐       ┌───────────────┐       │  特征宽表     │
│  链上数据API  │  →→→  │ 链上数据处理   │  →→→  │               │
└───────────────┘       └───────────────┘       │               │
                                                 └───────────────┘
┌───────────────┐       ┌───────────────┐              ↑
│  行为事件表   │  →→→  │ Onchain行为   │  →→→→→→→→→→→→→┘
└───────────────┘       │ 统计处理      │
                        └───────────────┘
```

**数据聚合频率**：

- 用户基本信息：每日同步增量更新
- POH信息：每日全量检查（有效期）
- 链上数据：每日更新（优先更新活跃用户）
- Onchain行为：每日聚合统计

##### 2. 标签数据流转流程

```
┌───────────────┐       ┌───────────────┐       ┌───────────────┐
│  标签定义     │  →→→  │ 规则解析服务   │  →→→  │ SQL生成       │
└───────────────┘       └───────────────┘       └───────┬───────┘
                                                         │
                        ┌───────────────┐       ┌───────▼───────┐
                        │ 标签用户映射表 │  ←←←  │ ClickHouse    │
                        └───────┬───────┘       │ 查询执行      │
                                │               └───────────────┘
                                │
                                ▼
                         [应用服务缓存]
```

**数据流转优化**：

- 预定义标签：使用物化视图自动更新（每日）
- 自定义标签：第一次计算结果存入标签用户映射表
- 大规模标签：分批计算和查询

##### 3. 投放数据流转流程

```
┌───────────────┐       ┌───────────────┐       ┌───────────────┐
│  投放定义     │  →→→  │ 审批服务      │  →→→  │ 投放状态管理  │
└───────────────┘       └───────────────┘       └───────┬───────┘
                                                         │
┌───────────────┐       ┌───────────────┐       ┌───────▼───────┐
│  标签服务     │  →→→  │ 目标用户获取   │  →→→  │ 投放用户映射表│
└───────────────┘       └───────────────┘       └───────┬───────┘
                                                         │
┌───────────────┐       ┌───────────────┐       ┌───────▼───────┐
│  C端请求      │  →→→  │ 投放展示服务   │  →→→  │ 投放内容返回  │
└───────────────┘       └───────────────┘       └───────────────┘
                                │
                        ┌───────▼───────┐       ┌───────────────┐
                        │ 埋点事件      │  →→→  │ 投放效果统计  │
                        │ 收集处理      │       └───────────────┘
                        └───────────────┘
```

**投放流程优化**：

- 投放生效时每日计算目标用户集并存储
- 用户请求时查询匹配的投放
- 每日聚合统计数据到MySQL

#### 可行性分析：

- **MySQL**:

  - 优势：事务支持，适合业务操作数据，如标签定义、投放配置等需要强一致性的数据
  - 劣势：不适合大规模分析查询和高并发读取
  - 解决方案：仅存储元数据和配置，将分析数据迁移到ClickHouse
- **ClickHouse**:

  - 优势：列式存储，高性能分析能力，适合存储特征宽表和行为事件数据
  - 劣势：不适合频繁更新，不支持事务
  - 解决方案：
    - 使用ReplacingMergeTree引擎处理用户特征更新
    - 行为事件数据使用按时间分区的MergeTree
    - 利用物化视图预计算常用标签
    - 批量写入减少写入压力

### 3. 数据处理与计算选型

#### 定时任务 + ClickHouse原生计算

| 技术               | 用途                                                           |
| ------------------ | -------------------------------------------------------------- |
| 定时任务           | - 离线特征计算 `<br>` - 批量标签更新 `<br>` - 定期数据聚合 |
| ClickHouse原生计算 | - 复杂查询计算 `<br>` - 特征统计 `<br>` - 物化视图自动更新 |
| 消息队列(Kafka)    | - 简单的消息处理 `<br>` - 异步事件处理 `<br>` - 数据流转   |

#### 定时任务详细设计

##### 1. 定时任务框架与调度

推荐使用**分布式定时任务调度框架**（如XXL-Job或自研调度器）管理所有计算任务，确保任务的可靠执行和监控。

| 任务类型          | 调度方式           | 任务特性                           | 失败处理策略           |
| ----------------- | ------------------ | ---------------------------------- | ---------------------- |
| 用户特征定期更新  | 每日Cron表达式调度 | 资源密集型，可并行执行             | 自动重试，告警通知     |
| 链上数据同步      | 每日固定时间       | 依赖外部API，需限流控制            | 熔断保护，增量同步     |
| 标签结果集更新    | 每日定时更新       | 计算复杂度与用户量和查询复杂度有关 | 分批处理，超时监控     |
| POH信息有效期检查 | 每日定时执行       | 关键业务逻辑，需保证准确性         | 人工干预，完整日志记录 |
| 统计数据聚合      | 每日低峰期执行     | 聚合计算，对数据库有压力           | 错峰执行，资源隔离     |

##### 2. 用户特征计算任务一览

根据《C端标签系统 - Onchain特征表.csv》中定义的字段更新频率要求，设计以下定时任务：

| 任务名称             | 更新频率     | 数据源         | 处理方式                          | 优先级 |
| -------------------- | ------------ | -------------- | --------------------------------- | ------ |
| POH_KYC有效期检查    | 每日凌晨2:00 | POH验证表      | 检查KYC认证有效期，过期则更新状态 | 高     |
| 链上数据_全量更新    | 每日凌晨3:00 | 第三方链上API  | 获取所有活跃用户的链上数据        | 中     |
| Onchain行为_统计任务 | 每日凌晨4:00 | 用户行为事件表 | 计算Onchain行为统计指标           | 高     |
| 用户特征_宽表合并    | 每日凌晨5:00 | 多数据源       | 合并各来源数据到用户特征宽表      | 中     |
| 预定义标签_更新任务  | 每日凌晨6:00 | 用户特征宽表   | 根据预定义规则更新标签用户集      | 中     |
| 投放效果_数据聚合    | 每日凌晨1:00 | 行为事件表     | 聚合投放效果指标到MySQL表         | 中     |

##### 3. 定时任务实现示例

**POH有效期检查任务**：

```go
// POH有效期检查任务 - 每日执行
func checkPohExpiration() {
    // 连接数据库
    db := connectToDB()
  
    // 获取所有KYC认证信息
    kycRecords, err := db.Query(`
        SELECT 
            user_id, 
            has_binance_kyc, binance_kyc_expire_time,
            has_okx_kyc, okx_kyc_expire_time,
            has_coinbase_kyc, coinbase_kyc_expire_time,
            has_bybit_kyc, bybit_kyc_expire_time,
            has_gate_kyc, gate_kyc_expire_time,
            has_kucoin_kyc, kucoin_kyc_expire_time
        FROM poh_verifications
        WHERE 
            has_binance_kyc = 1 OR has_okx_kyc = 1 OR has_coinbase_kyc = 1 OR 
            has_bybit_kyc = 1 OR has_gate_kyc = 1 OR has_kucoin_kyc = 1
    `)
  
    if err != nil {
        log.Fatalf("查询KYC记录失败: %v", err)
    }
  
    // 处理过期记录
    now := time.Now()
    for kycRecords.Next() {
        var record KycRecord
        // 扫描记录...
    
        // 检查过期状态并更新
        updates := []string{}
        if record.HasBinanceKyc && record.BinanceKycExpireTime.Before(now) {
            updates = append(updates, "has_binance_kyc = 0")
        }
        // 检查其他KYC...
    
        if len(updates) > 0 {
            updateSQL := fmt.Sprintf("UPDATE poh_verifications SET %s WHERE user_id = ?", 
                strings.Join(updates, ", "))
            db.Exec(updateSQL, record.UserID)
        
            // 更新特征宽表
            updateFeatureTable(record.UserID)
        }
    }
  
    // 记录任务执行结果
    log.Printf("POH有效期检查完成，处理了%d条记录，更新了%d条记录", totalCount, updatedCount)
}
```

**链上数据更新任务**：

```go
// 链上数据全量更新任务 - 每日执行
func updateOnchainData() {
    // 获取活跃用户列表
    activeUsers, err := getActiveUsers(30) // 最近30天活跃用户
    if err != nil {
        log.Fatalf("获取活跃用户失败: %v", err)
    }
  
    // 创建工作池
    workerpool := createWorkerPool(10) // 10个并发worker
  
    // 分批处理用户
    batchSize := 100
    for i := 0; i < len(activeUsers); i += batchSize {
        end := i + batchSize
        if end > len(activeUsers) {
            end = len(activeUsers)
        }
    
        batch := activeUsers[i:end]
        workerpool.Submit(func() {
            processUserBatch(batch)
        })
    }
  
    // 等待所有任务完成
    workerpool.Wait()
  
    // 记录任务执行结果
    log.Printf("链上数据更新完成，处理了%d个用户", len(activeUsers))
}

// 处理用户批次
func processUserBatch(users []User) {
    for _, user := range users {
        // 获取用户钱包地址
        wallets, err := getUserWallets(user.ID)
        if err != nil {
            log.Printf("获取用户钱包失败: %v", err)
            continue
        }
    
        for _, wallet := range wallets {
            // 调用第三方API获取链上数据
            onchainData, err := thirdwaveAPI.GetWalletData(wallet.Address)
            if err != nil {
                log.Printf("获取钱包数据失败: %v", err)
                continue
            }
        
            // 转换数据结构
            transformedData := transformOnchainData(onchainData)
        
            // 更新到ClickHouse
            err = updateClickHouseOnchainData(user.ID, wallet.Address, transformedData)
            if err != nil {
                log.Printf("更新ClickHouse失败: %v", err)
            }
        }
    }
}
```

**Onchain行为统计任务**：

```go
// Onchain行为统计任务 - 每日执行
func calculateOnchainBehaviorStats() {
    // 连接ClickHouse
    conn := connectToClickHouse()
  
    // 计算总Onchain行为统计
    _, err := conn.Exec(`
        INSERT INTO user_features
        SELECT
            user_id,
            countIf(event_type IN ('onchain_quest_complete', 'onchain_task_complete')) as onchain_action_total,
            countIf(event_type IN ('onchain_quest_complete', 'onchain_task_complete') 
                   AND event_time > date_sub(day, 30, now())) as onchain_action_30d,
            countIf(event_type IN ('onchain_quest_complete', 'onchain_task_complete') 
                   AND event_time > date_sub(day, 7, now())) as onchain_action_7d,
            countIf(event_type = 'onchain_quest_complete') as onchain_quest_total,
            countIf(event_type = 'onchain_task_complete') as onchain_task_total,
            now() as data_update_time,
            'scheduled_task' as data_source
        FROM user_events
        WHERE event_time > date_sub(month, 6, now())
        GROUP BY user_id
        SETTINGS optimize_on_insert=0
    `)
  
    if err != nil {
        log.Fatalf("Onchain行为统计失败: %v", err)
    }
  
    // 执行表优化
    conn.Exec("OPTIMIZE TABLE user_features FINAL")
  
    // 记录任务执行结果
    log.Printf("Onchain行为统计完成")
}
```

**预定义标签更新任务**：

```go
// 预定义标签更新任务 - 每日执行
func updatePredefinedLabels() {
    // 连接数据库
    db := connectToClickHouse()
    mysql := connectToMySQL()
  
    // 获取预定义标签列表
    labels, err := mysql.Query("SELECT id, filter_conditions FROM labels WHERE creator_id = 0") // 系统预定义标签
    if err != nil {
        log.Fatalf("获取预定义标签失败: %v", err)
    }
  
    // 逐个更新标签
    for labels.Next() {
        var id int64
        var filterJSON string
        labels.Scan(&id, &filterJSON)
    
        // 解析过滤条件
        filter, err := parseFilterConditions(filterJSON)
        if err != nil {
            log.Printf("解析标签过滤条件失败: %v", err)
            continue
        }
    
        // 将过滤条件转换为SQL
        sql, params := buildLabelSQL(filter)
    
        // 清除旧数据
        _, err = mysql.Exec("DELETE FROM label_user_mapping WHERE label_id = ?", id)
        if err != nil {
            log.Printf("清除旧标签映射失败: %v", err)
            continue
        }
    
        // 执行查询获取匹配用户
        rows, err := db.Query(sql, params...)
        if err != nil {
            log.Printf("执行标签查询失败: %v", err)
            continue
        }
    
        // 批量插入新映射
        batch, err := mysql.Prepare("INSERT INTO label_user_mapping (label_id, user_id, update_time) VALUES (?, ?, NOW())")
        if err != nil {
            log.Printf("准备批量插入失败: %v", err)
            continue
        }
    
        var userCount int
        for rows.Next() {
            var userID int64
            rows.Scan(&userID)
            batch.Exec(id, userID)
            userCount++
        }
    
        // 更新标签用户计数
        mysql.Exec("UPDATE labels SET user_count = ? WHERE id = ?", userCount, id)
    
        log.Printf("标签 %d 更新完成，匹配用户 %d 人", id, userCount)
    }
}
```

##### 4. 数据计算性能优化

**增量计算策略**：

```sql
-- 增量计算示例：链上交易统计数据
CREATE TABLE onchain_tx_stats_daily (
    user_id UInt64,
    wallet_address String,
    date Date,
    tx_count UInt32,
    tx_value_usd Float64,
    erc20_transfers UInt32,
    native_transfers UInt32,
    update_time DateTime
) ENGINE = SummingMergeTree()
PARTITION BY toYYYYMM(date)
ORDER BY (user_id, wallet_address, date);

-- 每日增量插入昨日数据
INSERT INTO onchain_tx_stats_daily
SELECT
    user_id,
    wallet_address,
    toDate(tx_time) as date,
    count() as tx_count,
    sum(value_usd) as tx_value_usd,
    countIf(token_type = 'ERC20') as erc20_transfers,
    countIf(token_type = 'NATIVE') as native_transfers,
    now() as update_time
FROM blockchain_transactions
WHERE tx_time >= yesterday() AND tx_time < today()
GROUP BY user_id, wallet_address, toDate(tx_time);

-- 更新检查点
INSERT INTO etl_checkpoints (task_name, last_process_time)
VALUES ('onchain_tx_stats', now());
```

**资源隔离与优先级**：

定时任务按优先级和资源需求分类，避免相互影响：

| 优先级   | 任务类型                     | 资源考虑                 | 执行策略                 |
| -------- | ---------------------------- | ------------------------ | ------------------------ |
| 高优先级 | POH信息更新、Onchain行为统计 | 计算复杂度中等           | 预留资源配额，可并行执行 |
| 中优先级 | 链上数据同步、用户特征更新   | 资源密集，但容忍一定延迟 | 错峰调度，批量处理       |
| 低优先级 | 历史数据归档、缓存预热       | 资源密集，延迟不敏感     | 低峰期执行，可中断恢复   |

**定时任务监控**：

1. **健康检查**：

   - 任务心跳监控
   - 执行时长异常告警
   - 失败重试自动触发
2. **资源监控**：

   - 数据库连接池使用率
   - ClickHouse查询资源占用
   - 内存和CPU使用情况
3. **业务指标监控**：

   - 数据同步延迟
   - 数据准确性校验
   - 标签用户数波动监控

##### 5. 具体定时任务列表及执行计划

以下是完整的定时任务列表，所有任务均为天级别：

| 任务ID | 任务名称              | 执行时间     | 依赖任务       | 描述                                |
| ------ | --------------------- | ------------ | -------------- | ----------------------------------- |
| T001   | 基础用户数据同步      | 每日 01:00   | 无             | 从MySQL同步用户基础信息到ClickHouse |
| T002   | POH有效期检查         | 每日 02:00   | 无             | 检查所有KYC认证的有效期并更新状态   |
| T003   | 链上数据更新-活跃用户 | 每日 03:00   | T001           | 更新最近30天活跃用户的链上数据      |
| T004   | 链上数据更新-全量用户 | 每日 03:30   | T003           | 更新其他用户的链上数据（轮询策略）  |
| T005   | Onchain行为统计计算   | 每日 04:00   | 无             | 计算用户Onchain行为指标             |
| T006   | 用户特征宽表合并      | 每日 05:00   | T002,T004,T005 | 合并各来源数据到用户特征宽表        |
| T007   | 系统预定义标签更新    | 每日 06:00   | T006           | 更新系统预定义标签的用户集          |
| T008   | 热门自定义标签更新    | 每日 07:00   | T006           | 更新使用频率高的自定义标签          |
| T009   | 投放目标用户计算      | 每日 08:00   | T007,T008      | 计算每个有效投放的目标用户集        |
| T010   | 投放效果数据统计      | 每日 01:30   | 无             | 聚合昨日的投放展示、点击等效果数据  |
| T011   | 用户分群统计报表      | 每日 09:00   | T006           | 生成用户分群统计报表                |
| T012   | 标签系统健康检查      | 每日 00:00   | 无             | 检查标签系统数据一致性和完整性      |
| T013   | 数据清理与归档        | 每周日 23:00 | 无             | 清理历史数据，归档过期数据          |

**执行顺序与资源安排**：

```
时间轴: |--01:00--|--02:00--|--03:00--|--04:00--|--05:00--|--06:00--|--07:00--|--08:00--|--09:00--|
任务:    T001,T010  T002     T003,T004  T005      T006      T007      T008      T009      T011
         (并行)               (并行)

* T012在每日0点执行
* T013在每周日23点执行
```

所有任务都采用天级别调度，确保数据整体一致性和资源合理利用。特定任务如T003和T004虽然同时段执行，但针对不同用户群体，避免资源竞争。

### 4. 数据埋点设计

#### 埋点数据处理流程

```
┌─────────────┬─────────────┬─────────────┬─────────────┐
1. **批处理模式**：

   - 使用轻量级消息队列（如Kafka配置）
   - 直接使用Golang消费者处理消息
   - 适度批处理后写入ClickHouse
2. **定时处理模式**：

   - 定时任务从ClickHouse读取原始数据
   - 执行聚合SQL计算用户特征
   - 更新用户标签和指标
   - 生成数据报表

```go
// 简化的埋点数据处理示例
func processTrackingEvents() {
	// 从Kafka获取埋点事件
	consumer, err := kafka.NewConsumer(&kafka.ConfigMap{
		"bootstrap.servers": "kafka:9092",
		"group.id":          "tracking_consumer_group",
		"auto.offset.reset": "latest",
	})
	if err != nil {
		log.Fatalf("创建Kafka消费者失败: %v", err)
	}

	// 订阅主题
	consumer.SubscribeTopics([]string{"tracking_events"}, nil)

	// 批量处理消息
	for {
		msg, err := consumer.ReadMessage(time.Second * 10)
		if err != nil {
			if err.(kafka.Error).Code() == kafka.ErrTimedOut {
				continue
			}
			log.Printf("读取消息失败: %v", err)
			continue
		}

		// 处理消息
		event := parseEvent(msg.Value)
		if event != nil {
			// 批处理收集
			batchProcessor.Add(event)
		}

		// 当批处理缓冲区满时写入ClickHouse
		if batchProcessor.IsFull() {
			events := batchProcessor.Flush()
			batchInsertToClickHouse(events)
		}
	}
}

// 批量插入到ClickHouse
func batchInsertToClickHouse(events []map[string]interface{}) error {
	// 准备批量插入语句
	batch, err := clickhouseDB.PrepareBatch(context.Background(), "INSERT INTO user_events")
	if err != nil {
		return fmt.Errorf("准备批量插入失败: %v", err)
	}

	// 添加所有事件到批次
	for _, event := range events {
		err := batch.Append(
			event["event_time"],
			event["user_id"],
			event["event_type"],
			event["page"],
			// 其他字段...
		)
		if err != nil {
			log.Printf("添加事件到批次失败: %v", err)
			continue
		}
	}

	// 执行批量插入
	if err := batch.Send(); err != nil {
		return fmt.Errorf("发送批次失败: %v", err)
	}

	return nil
}
```

## 5. 数据埋点规范（建议部分）2.0.0 需求 技术选型

### 5.1 埋点基本原则

1. **埋点目标明确**

   - 每个埋点必须有明确的业务目标和数据用途
   - 埋点应覆盖用户全生命周期的关键行为
   - 埋点粒度应满足分析需求但不过度收集
2. **命名规范统一**

   - 埋点事件命名：[模块]_[行为]_[对象]，如 quest_view_detail
   - 属性命名：采用驼峰命名法，如 userType, questId
   - 公共属性与特有属性分离，避免冗余
3. **数据质量保障**

   - 埋点必须进行版本控制，记录变更历史
   - 新增埋点必须通过测试验证后方可上线
   - 关键埋点需配置监控告警机制

### 5.2 埋点事件类型

1. **页面访问事件**

   - 事件名：page_view
   - 触发时机：用户访问页面时
   - 基本属性：
     - pageId: 页面唯一标识
     - pageName: 页面名称
     - pageUrl: 页面URL
     - referrer: 来源页面
     - viewDuration: 浏览时长(ms)
2. **用户行为事件**

   - 事件名：user_action
   - 触发时机：用户执行特定操作时
   - 基本属性：
     - actionType: 行为类型，如 click, submit, select
     - actionTarget: 行为目标，如 button, form, dropdown
     - actionPosition: 行为发生位置
     - actionResult: 行为结果，如 success, fail
3. **业务流程事件**

   - 事件名：business_process
   - 触发时机：业务流程关键节点
   - 基本属性：
     - processType: 流程类型，如 registration, quest_completion
     - processStep: 流程步骤
     - processStatus: 流程状态，如 start, processing, complete
     - processDuration: 流程耗时(ms)
4. **系统事件**

   - 事件名：system_event
   - 触发时机：系统状态变化或异常情况
   - 基本属性：
     - eventType: 事件类型，如 error, warning, notification
     - eventCode: 事件代码
     - eventMessage: 事件描述信息
     - eventSeverity: 严重程度，如 high, medium, low

### 5.3 埋点属性字段规范

1. **公共属性**

   - userId: 用户唯一标识
   - sessionId: 会话标识
   - timestamp: 事件发生时间戳
   - platform: 平台，如 web, ios, android
   - version: 应用版本号
   - userAgent: 用户代理信息
   - deviceInfo: 设备信息
2. **Quest模块特有属性**

   - questId: Quest唯一标识
   - questType: Quest类型，如 twitter, discord, onchain
   - questCategory: Quest分类
   - questStatus: Quest状态，如 available, in_progress, completed
   - rewardType: 奖励类型，如 token, nft, whitelist
   - rewardAmount: 奖励数量
3. **社交绑定模块特有属性**

   - socialType: 社交平台类型，如 twitter, discord
   - bindStatus: 绑定状态，如 success, fail, pending
   - verificationMethod: 验证方法
   - accountInfo: 账号信息
4. **链上操作模块特有属性**

   - chainType: 链类型，如 ethereum, solana
   - walletAddress: 钱包地址
   - transactionType: 交易类型，如 swap, stake, mint
   - transactionStatus: 交易状态，如 pending, confirmed, failed
   - gasUsed: 使用的gas量
   - tokenAmount: 代币数量
   - usdValue: 美元价值

### 5.4 埋点实施流程

1. **埋点设计与评审**

   - 产品与数据团队共同确定埋点需求
   - 填写埋点设计文档，明确事件定义和属性
   - 召开埋点评审会，确保埋点满足分析需求
2. **埋点开发与测试**

   - 开发团队根据埋点文档实现埋点代码
   - 在测试环境验证埋点数据准确性
   - 配置埋点监控仪表盘，验证数据完整性
3. **埋点上线与维护**

   - 埋点代码随功能发布上线
   - 定期检查埋点数据质量，确保持续可用
   - 建立埋点变更管理流程，记录埋点生命周期

### 5.5 埋点数据处理流程

1. **数据采集层**

   - 客户端SDK负责采集原始埋点数据
   - 实施实时发送与批量发送两种模式
   - 确保网络异常情况下的数据持久化与重发
2. **数据清洗层**

   - 对原始埋点数据进行格式校验
   - 过滤无效或恶意数据
   - 数据标准化处理，确保格式统一
3. **数据存储层**

   - 实时数据流处理入库
   - 分层存储：原始数据、清洗数据、聚合数据
   - 实施数据生命周期管理策略
4. **数据应用层**

   - 构建实时数据大盘
   - 支持自定义数据分析查询
   - 为标签系统提供数据支持

### 5.6 埋点数据与标签系统集成

1. **埋点数据特征提取**

   - 基于埋点数据计算用户行为特征
   - 特征包括：活跃度、参与度、偏好度等
   - 特征更新频率与数据实时性要求匹配
2. **标签规则映射**

   - 埋点特征与标签规则建立映射关系
   - 支持基于埋点数据的复合标签创建
   - 埋点变更时同步更新相关标签规则
3. **效果反馈闭环**

   - 监控标签人群对特定事件的触发率
   - 评估标签精准度与业务价值
   - 持续优化埋点设计与标签规则

### 5.7 埋点监控与告警机制

1. **埋点健康监控**

   - 监控关键埋点的数据量变化趋势
   - 设置异常波动阈值，如±30%触发告警
   - 建立埋点数据延迟监控，确保实时性
2. **数据质量告警**

   - 监控数据完整性，如必填字段缺失率
   - 监控数据准确性，如格式错误、异常值
   - 配置数据一致性检查，如总和校验
3. **告警处理流程**

   - 建立告警分级响应机制
   - 配置告警通知渠道与责任人
   - 记录告警处理过程与解决方案

### 5.8 埋点性能优化

1. **客户端性能考虑**

   - 埋点代码轻量化，避免影响页面加载速度
   - 采用批量发送机制减少网络请求次数
   - 非关键事件采用延迟发送或空闲时发送
2. **服务端性能考虑**

   - 采用分布式处理架构应对高并发
   - 实施数据分片策略提高查询效率
   - 配置数据预计算减少实时计算压力
3. **存储优化策略**

   - 实施数据压缩减少存储成本
   - 配置数据冷热分离策略
   - 建立数据归档与清理机制

### 6. 标签系统架构选型

#### 推荐方案：基于规则引擎的标签系统

```
┌─────────────────────────────────────────────────────────────┐
│                     标签管理界面                             │
└───────────────────────────────┬─────────────────────────────┘
                                │
┌───────────────────────────────┼─────────────────────────────┐
│                          标签规则引擎                        │
├─────────────────┬─────────────┼─────────────┬───────────────┤
│   条件解析器    │    表达式计算器   │   结果过滤器   │
└─────────────────┴─────────────┼─────────────┴───────────────┘
                                │
┌───────────────────────────────┼─────────────────────────────┐
│                          数据访问层                          │
└───────────────────────────────┼─────────────────────────────┘
                                │
┌─────────────────┬─────────────┼──────────────────────────────┐
│     MySQL       │    ClickHouse    │      应用服务缓存       │
└─────────────────┴─────────────────┴──────────────────────────┘
```

#### 可行性分析：

- **优势**：灵活性高，支持复杂规则，易于扩展
- **劣势**：复杂规则可能影响性能，需要优化查询
- **解决方案**：
  - 使用Drools规则引擎管理复杂规则
  - 实现规则到SQL/查询的高效转换
  - 标签预计算+实时计算结合

### 7. 实时/近实时数据处理选型

#### 轻量级消息队列 + Golang工作线程

| 技术           | 用途                                                           |
| -------------- | -------------------------------------------------------------- |
| Kafka          | - 事件收集 `<br>` - 消息缓冲 `<br>` - 解耦生产和消费       |
| Golang工作线程 | - 消息处理 `<br>` - 简单数据转换 `<br>` - 写入存储         |
| 应用服务缓存   | - 查询结果缓存 `<br>` - 计算结果缓存 `<br>` - 避免重复计算 |

#### 可行性分析：

- **轻量级消息队列**:

  - 优势：配置简单，维护成本低，足够处理中等规模数据
  - 劣势：吞吐量和可靠性不如完整Kafka集群
  - 解决方案：合理设置消息过期策略，实现简单的重试机制
- **Golang工作线程**:

  - 优势：开发简单，充分利用Golang并发优势
  - 劣势：复杂处理逻辑需要自行实现
  - 解决方案：合理设计消费者组，实现优雅退出和错误处理

#### 实现示例：

```go
// 简化的实时处理示例
func startWorkers(workerCount int) {
	for i := 0; i < workerCount; i++ {
		go func(workerID int) {
			for {
				// 获取任务
				messages := fetchFromQueue("tracking_events", 100)

				if len(messages) == 0 {
					time.Sleep(time.Second)
					continue
				}

				// 批量处理
				processedEvents := make([]map[string]interface{}, 0, len(messages))
				for _, msg := range messages {
					// 处理单条消息
					event := processMessage(msg)
					if event != nil {
						processedEvents = append(processedEvents, event)
					}
				}

				// 批量写入ClickHouse
				if len(processedEvents) > 0 {
					err := batchWriteToClickHouse(processedEvents)
					if err != nil {
						// 错误处理和重试逻辑
						handleWriteError(err, processedEvents)
					}
				}

				// 确认处理完成
				acknowledgeMessages(messages)
			}
		}(i)
	}
}
```

### 8. API/服务层选型

#### 推荐方案：Golang + GraphQL

| 技术   | 用途                                                            |
| ------ | --------------------------------------------------------------- |
| Golang | - 基础服务框架 `<br>` - 高性能API服务 `<br>` - 业务逻辑实现 |
| Gin    | - Web框架 `<br>` - 路由管理 `<br>` - 中间件支持             |
| gqlgen | - GraphQL实现 `<br>` - 类型安全 `<br>` - 高性能查询         |

#### 可行性分析：

- **Golang**:

  - 优势：高性能、低内存占用、并发支持强、编译型语言
  - 劣势：生态系统相比Java较小，一些企业级功能需自行实现
  - 解决方案：利用成熟的Golang框架，组合解决企业级需求
- **Gin + gqlgen**:

  - 优势：轻量高效，类型安全，适合构建高性能API
  - 劣势：相比成熟的Java框架，需要更多手动配置
  - 解决方案：构建可复用的中间件和工具库

#### 服务实现示例：

```go
// Golang标签服务示例
package main

import (
	"github.com/gin-gonic/gin"
	"gorm.io/gorm"
)

type LabelService struct {
	db    *gorm.DB
	cache *ApplicationCache
}

func NewLabelService(db *gorm.DB, cache *ApplicationCache) *LabelService {
	return &LabelService{db: db, cache: cache}
}

func (s *LabelService) GetUsersByLabel(labelID string, limit, offset int) ([]User, error) {
	// 先尝试从应用缓存获取
	cacheKey := fmt.Sprintf("label:%s:users:%d:%d", labelID, limit, offset)
	cachedUsers := s.cache.Get(cacheKey)
	if cachedUsers != nil {
		return cachedUsers.([]User), nil
	}

	// 缓存未命中，查询数据库
	var users []User
	label, err := s.getLabelDefinition(labelID)
	if err != nil {
		return nil, err
	}

	// 构建查询条件
	query := s.buildClickHouseQuery(label)

	// 执行查询
	result, err := s.executeClickHouseQuery(query, limit, offset)
	if err != nil {
		return nil, err
	}

	// 设置缓存
	s.cache.Set(cacheKey, result, time.Hour) // 缓存1小时

	return result, nil
}

func setupRouter() *gin.Engine {
	r := gin.Default()
	r.Use(TrackingMiddleware()) // 使用埋点中间件

	labelService := initLabelService()

	r.GET("/api/labels", func(c *gin.Context) {
		// 获取所有标签
		labels, err := labelService.GetAllLabels()
		if err != nil {
			c.JSON(500, gin.H{"error": err.Error()})
			return
		}
		c.JSON(200, labels)
	})

	r.GET("/api/labels/:id/users", func(c *gin.Context) {
		labelID := c.Param("id")
		limit := c.DefaultQuery("limit", "100")
		offset := c.DefaultQuery("offset", "0")

		limitInt, _ := strconv.Atoi(limit)
		offsetInt, _ := strconv.Atoi(offset)

		users, err := labelService.GetUsersByLabel(labelID, limitInt, offsetInt)
		if err != nil {
			c.JSON(500, gin.H{"error": err.Error()})
			return
		}

		c.JSON(200, users)
	})

	return r
}

func main() {
	r := setupRouter()
	r.Run(":8080")
} 
```

### 9. 前端技术选型

#### 推荐方案：Vue3 + Element Plus

| 技术         | 用途                                                                 |
| ------------ | -------------------------------------------------------------------- |
| Vue3         | - 用户界面构建 `<br>` - 组件化开发 `<br>` - 前端响应式系统       |
| Element Plus | - UI组件库 `<br>` - 后台管理界面组件 `<br>` - 表单控件和数据表格 |
| Pinia        | - 状态管理 `<br>` - 组件通信 `<br>` - 持久化数据                 |
| Vue Router   | - 路由管理 `<br>` - 页面跳转 `<br>` - 权限控制                   |

#### 可行性分析：

- **Vue3 + Element Plus**:
  - 优势：组合式API更灵活，TypeScript支持更好，响应式系统升级，开发效率高
  - 劣势：相比Vue2生态还在发展中，部分旧插件可能不兼容
  - 解决方案：使用Vite加速开发，充分利用新特性提高代码质量和维护性

#### 前端埋点实现：

```typescript
// Vue3埋点实现 - useTracker.ts
import { App, Plugin } from 'vue'

export interface TrackEvent {
  event_type: string
  [key: string]: any
}

export interface TrackerOptions {
  appId: string
  serverUrl: string
  autoTrackPageView?: boolean
  sampleRate?: number
}

export const useTracker = () => {
  const trackEvent = (event: TrackEvent) => {
    // 添加公共属性
    const enrichedEvent = {
      ...event,
      app_id: window.__TRACKER_APP_ID__,
      timestamp: new Date().toISOString(),
      session_id: getSessionId(),
      user_id: getUserId(),
      url: window.location.href,
      referrer: document.referrer
    }
  
    // 发送埋点数据
    sendToServer(enrichedEvent)
  }
  
  const sendToServer = (event: any) => {
    if (navigator.sendBeacon) {
      navigator.sendBeacon(window.__TRACKER_SERVER_URL__, JSON.stringify(event))
    } else {
      // 降级处理
      fetch(window.__TRACKER_SERVER_URL__, {
        method: 'POST',
        body: JSON.stringify(event),
        keepalive: true,
        headers: {
          'Content-Type': 'application/json'
        }
      }).catch(err => console.error('埋点发送失败:', err))
    }
  }
  
  return {
    trackEvent
  }
}

// 创建Vue插件 - tracker.ts
export const createTracker = (options: TrackerOptions): Plugin => {
  return {
    install(app: App) {
      // 全局配置
      window.__TRACKER_APP_ID__ = options.appId
      window.__TRACKER_SERVER_URL__ = options.serverUrl
  
      // 自动页面浏览埋点
      if (options.autoTrackPageView) {
        const { trackEvent } = useTracker()
  
        app.config.globalProperties.$router?.beforeEach((to, from, next) => {
          // 路由变化时触发埋点
          next()
        })
  
        app.config.globalProperties.$router?.afterEach((to) => {
          trackEvent({
            event_type: 'page_view',
            page_path: to.path,
            page_name: to.name
          })
        })
      }
  
      // 提供全局方法
      app.config.globalProperties.$trackEvent = useTracker().trackEvent
  
      // 提供组合式API
      app.provide('tracker', useTracker())
    }
  }
}
```

### 10. ClickHouse特性应用

基于业务已有ClickHouse基础，重点利用以下特性：

| 特性               | 应用场景                                                                       |
| ------------------ | ------------------------------------------------------------------------------ |
| 物化视图           | - 预计算常用标签组合 `<br>` - 加速分群统计查询 `<br>` - 维护衍生指标       |
| 分布式表           | - 横向扩展数据容量 `<br>` - 提高并行查询能力 `<br>` - 支持数据分片         |
| 稀疏索引           | - 优化高基数字段查询 `<br>` - 减少数据扫描量 `<br>` - 提高复杂条件查询性能 |
| 字典功能           | - 存储维度数据 `<br>` - 加速关联查询 `<br>` - 减少JOIN操作                 |
| 数组和嵌套数据结构 | - 存储用户标签集合 `<br>` - 存储多值属性 `<br>` - 优化一对多关系查询       |

#### 特性应用示例：

**1. 物化视图示例（预计算活跃用户标签）**:

```sql
CREATE MATERIALIZED VIEW mv_active_users
ENGINE = AggregatingMergeTree()
PARTITION BY toYYYYMM(create_time)
ORDER BY (user_id)
AS SELECT
    user_id,
    maxState(if(action_type = 'login', toDate(create_time), NULL)) as last_login,
    countState(if(action_type = 'quest_complete', 1, NULL)) as quest_complete_count,
    countState(if(action_type = 'onchain_action', 1, NULL)) as onchain_action_count
FROM user_actions
GROUP BY user_id;
```

**2. 字典应用示例（Token价值评估）**:

```sql
CREATE DICTIONARY token_values (
    token_address String,
    token_symbol String,
    token_value Float64,
    update_time DateTime
)
PRIMARY KEY token_address
SOURCE(HTTP(URL 'http://price-service/tokens'))
LIFETIME(300)
LAYOUT(HASHED());
```

**3. 数组存储示例（用户持有Token列表）**:

```sql
CREATE TABLE user_token_holdings (
    user_id UInt64,
    wallet_address String,
    token_addresses Array(String),
    token_symbols Array(String),
    token_amounts Array(Float64),
    update_time DateTime
)
ENGINE = MergeTree()
PARTITION BY toYYYYMM(update_time)
ORDER BY (user_id, wallet_address);
```

### 11. 数据同步策略

从MySQL到ClickHouse的数据同步策略：

| 同步方式     | 适用场景                                                         | 实现方式                        |
| ------------ | ---------------------------------------------------------------- | ------------------------------- |
| 简化CDC同步  | - 用户基本信息 `<br>` - 账户变更数据 `<br>` - 关键业务状态   | Debezium + Kafka + Golang消费者 |
| 定时批量同步 | - 标签元数据 `<br>` - 历史统计数据 `<br>` - 非实时业务数据   | Go定时任务 + 直接数据库查询同步 |
| 应用层同步   | - 关键业务数据 `<br>` - 双写模式 `<br>` - 实时性要求高的数据 | 业务代码中实现双写              |

#### 数据同步实现示例：

**1. 使用Debezium的配置**:

```json
{
  "name": "mysql-connector",
  "config": {
    "connector.class": "io.debezium.connector.mysql.MySqlConnector",
    "database.hostname": "mysql-master",
    "database.port": "3306",
    "database.user": "debezium",
    "database.password": "dbz",
    "database.server.id": "1",
    "database.server.name": "mysql-server",
    "database.include.list": "user_db",
    "table.include.list": "user_db.users,user_db.labels",
    "database.history.kafka.bootstrap.servers": "kafka:9092",
    "database.history.kafka.topic": "schema-changes",
    "include.schema.changes": "true"
  }
}
```

**2. Golang的定时批量同步工具**:

```go
// 定时批量同步示例 - 每日执行
func syncDataFromMySQLToClickHouse() {
	// 创建MySQL连接
	mysqlDB, err := sql.Open("mysql", "user:password@tcp(mysql-host:3306)/user_db")
	if err != nil {
		log.Fatalf("MySQL连接失败: %v", err)
	}
	defer mysqlDB.Close()

	// 创建ClickHouse连接
	clickhouseDB, err := sql.Open("clickhouse", "tcp://clickhouse-host:9000?database=user_db")
	if err != nil {
		log.Fatalf("ClickHouse连接失败: %v", err)
	}
	defer clickhouseDB.Close()

	// 获取上次同步时间
	lastSyncTime := getLastSyncTime()

	// 查询变更数据
	rows, err := mysqlDB.Query(
		"SELECT id, name, properties, updated_at FROM labels WHERE updated_at > ?",
		lastSyncTime,
	)
	if err != nil {
		log.Fatalf("查询失败: %v", err)
	}
	defer rows.Close()

	// 准备批量写入数据
	tx, err := clickhouseDB.Begin()
	if err != nil {
		log.Fatalf("开始事务失败: %v", err)
	}

	stmt, err := tx.Prepare("INSERT INTO labels (id, name, properties, updated_at) VALUES (?, ?, ?, ?)")
	if err != nil {
		log.Fatalf("准备语句失败: %v", err)
	}

	// 批量插入
	count := 0
	for rows.Next() {
		var id int
		var name string
		var properties string
		var updatedAt time.Time

		if err := rows.Scan(&id, &name, &properties, &updatedAt); err != nil {
			log.Printf("扫描行失败: %v", err)
			continue
		}

		if _, err := stmt.Exec(id, name, properties, updatedAt); err != nil {
			log.Printf("执行插入失败: %v", err)
			continue
		}

		count++
	}

	// 提交事务
	if err := tx.Commit(); err != nil {
		log.Fatalf("提交事务失败: %v", err)
	}

	log.Printf("成功同步 %d 条记录", count)

	// 更新同步时间
	updateLastSyncTime(time.Now())
}

// 设置定时任务
func setupSyncTasks() {
	c := cron.New()

	// 每日凌晨2点同步标签数据
	c.AddFunc("0 2 * * *", func() { syncDataFromMySQLToClickHouse() })

	c.Start()
}
```

**3. 应用层双写示例**:

```go
// 业务层双写示例
func CreateLabel(label *Label) error {
	// 开始事务
	tx, err := mysqlDB.Begin()
	if err != nil {
		return fmt.Errorf("开始MySQL事务失败: %v", err)
	}

	// MySQL写入
	result, err := tx.Exec(
		"INSERT INTO labels (name, properties, created_at, updated_at) VALUES (?, ?, ?, ?)",
		label.Name, label.Properties, time.Now(), time.Now(),
	)
	if err != nil {
		tx.Rollback()
		return fmt.Errorf("MySQL写入失败: %v", err)
	}

	// 获取插入ID
	labelID, err := result.LastInsertId()
	if err != nil {
		tx.Rollback()
		return fmt.Errorf("获取插入ID失败: %v", err)
	}

	// 提交MySQL事务
	if err := tx.Commit(); err != nil {
		return fmt.Errorf("提交MySQL事务失败: %v", err)
	}

	// 异步写入ClickHouse
	go func(id int64, lbl *Label) {
		if err := insertLabelToClickHouse(id, lbl); err != nil {
			// 记录错误并加入重试队列
			log.Printf("ClickHouse写入失败: %v", err)
			addToRetryQueue("label_insert", id, lbl)
		}
	}(labelID, label)

	return nil
}

// ClickHouse写入
func insertLabelToClickHouse(id int64, label *Label) error {
	_, err := clickhouseDB.Exec(
		"INSERT INTO labels (id, name, properties, created_at, updated_at) VALUES (?, ?, ?, ?, ?)",
		id, label.Name, label.Properties, time.Now(), time.Now(),
	)
	return err
}
```

## 四、性能优化与扩展性考虑

### 1. 查询性能优化策略

| 策略           | 简化实现方式                                                           |
| -------------- | ---------------------------------------------------------------------- |
| 预计算常用标签 | - ClickHouse物化视图 `<br>` - 定时更新汇总表 `<br>` - 标签实时更新 |
| 应用层缓存机制 | - 应用内存缓存 `<br>` - 分布式缓存 `<br>` - 合理设置过期时间       |
| 查询优化       | - 优化SQL `<br>` - 索引管理 `<br>` - 减少JOIN操作                  |
| 数据分区       | - 按时间分区 `<br>` - 冷热数据分离 `<br>` - 自动分区管理           |

### 2. 水平扩展能力

| 组件       | 扩展策略                                                      |
| ---------- | ------------------------------------------------------------- |
| ClickHouse | - 集群模式部署 `<br>` - 分片 + 副本架构 `<br>` - 分布式表 |
| 应用服务   | - 无状态设计 `<br>` - 容器化部署 `<br>` - 自动扩缩容      |
| Kafka      | - 分区扩展 `<br>` - 消费组并行处理 `<br>` - 集群节点扩展  |

### 3. 容量规划

基于需求文档的数据量估算：

| 数据类型     | 估算容量            | 增长率       | 存储选择                       |
| ------------ | ------------------- | ------------ | ------------------------------ |
| 用户基础数据 | 100万用户 × 20字段 | 日增5000用户 | MySQL + ClickHouse             |
| 行为数据     | 日均1000万条记录    | 月增30%      | ClickHouse                     |
| 链上数据     | 日均500万条交易     | 月增25%      | ClickHouse                     |
| 标签数据     | 15000个标签定义     | 月增500标签  | MySQL(定义) + ClickHouse(结果) |

## 五、技术风险评估与解决方案

| 风险点               | 影响等级 | 简化解决方案                                                     |
| -------------------- | -------- | ---------------------------------------------------------------- |
| 复杂查询性能不足     | 高       | - 预计算结果表 `<br>` - 定时更新汇总表 `<br>` - 优化SQL查询  |
| 大量标签导致存储膨胀 | 中       | - 冷热数据分离 `<br>` - 数据压缩 `<br>` - 定期清理过期数据   |
| 实时更新与查询冲突   | 中       | - 读写分离 `<br>` - 批量写入 `<br>` - 非高峰期进行大规模计算 |
| 数据一致性保障       | 高       | - 简化CDC同步 `<br>` - 定期校验数据 `<br>` - 数据修复工具    |
| 系统扩展性瓶颈       | 中       | - 模块化设计 `<br>` - 服务分层 `<br>` - 计算与存储分离       |
| 埋点数据量激增       | 中       | - 数据抽样 `<br>` - 简化存储字段 `<br>` - 数据分级存储       |
| 埋点系统稳定性       | 高       | - 异步写入 `<br>` - 本地缓冲队列 `<br>` - 简单降级机制       |

## 六、实施路径规划

### 阶段一：基础架构搭建

1. MySQL与ClickHouse数据模型设计
2. 简化数据同步方案实现（Debezium或定时任务）
3. 基础微服务框架搭建（Golang）
4. 标签规则引擎核心实现
5. 埋点系统基础架构搭建

### 阶段二：核心功能开发

1. 标签管理界面实现
2. 规则到查询转换器实现
3. 基础预定义标签集实现
4. 用户画像服务开发
5. 前端埋点SDK实现
6. 后端埋点中间件实现

### 阶段三：性能优化与扩展

1. 标签查询性能优化
2. 应用缓存机制实现
3. 批处理计算优化
4. 数据存储优化

### 阶段四：集成与上线

1. 与投放系统集成
2. 功能测试与性能测试
3. 生产环境部署
4. 系统监控配置

## 七、总结与建议

### 技术选型总结

本技术选型方案基于现有MySQL+ClickHouse架构，提出了一套标签系统解决方案，避免了对大数据处理框架的依赖。核心技术栈包括：

- 存储层：MySQL + ClickHouse（无Redis）
- 计算层：每日定时任务 + ClickHouse原生计算
- 服务层：Golang + Gin + gqlgen
- 前端层：Vue3 + Element Plus
- 数据同步：Debezium/定时任务 + 消息队列
- 埋点系统：前端SDK + Golang中间件 + 处理管道

### 最终建议

1. **充分利用ClickHouse优势**：利用ClickHouse强大的分析能力和物化视图功能，无需额外的大数据处理框架。
2. **简化分布式计算**：用每日定时批处理任务替代复杂的实时计算，降低开发和维护成本。
3. **模块化设计**：系统设计采用模块化结构，允许将来在需要时逐步引入更复杂的技术组件。
4. **重视数据质量**：确保数据校验和监控机制到位，保障数据准确性。
5. **降低技术门槛**：选择成熟、易用的技术组件，降低开发团队的学习曲线。
6. **埋点系统精简**：简化埋点处理流程，确保高效稳定的同时不引入过多复杂性。
7. **Golang性能优势**：充分利用Golang在并发处理方面的优势，特别是在数据处理和API服务层面。
8. **天级别数据更新**：所有数据任务均采用每日更新策略，减少系统复杂度，提高可靠性。

### 核心技术决策摘要

| 决策点         | 选择方案               | 技术理由                                 |
| -------------- | ---------------------- | ---------------------------------------- |
| 缓存方案       | 应用层缓存而非Redis    | 降低基础设施复杂性，减少维护成本         |
| 数据更新频率   | 全部采用天级别更新     | 简化系统设计，提高稳定性，满足业务需求   |
| 标签计算方式   | 预计算+按需计算相结合  | 平衡系统性能与实时性需求                 |
| 微服务拆分粒度 | 按核心业务领域拆分     | 清晰的服务边界，支持不同团队独立开发维护 |
| 定时任务调度   | 分布式定时任务框架     | 可靠的任务执行与监控                     |
| 链上数据获取   | 基于批处理的天级别更新 | 平衡API调用成本与数据新鲜度              |
